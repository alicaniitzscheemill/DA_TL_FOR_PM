{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import Dataloader_mmd_ce\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabiankolb/Documents/Universität/TUM_Master/Masterarbeit/CODE/DA_TL_FOR_PM/DOMAIN_ADAPTION/Dataloader_mmd_ce.py:38: UserWarning: Not all elements were covered\n",
      "  warnings.warn(\"Not all elements were covered\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/60 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/046_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (150, 9, 1024), Y_shape: (150,)\n",
      "2/60 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/037_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (300, 9, 1024), Y_shape: (300,)\n",
      "3/60 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/041_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (450, 9, 1024), Y_shape: (450,)\n",
      "4/60 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/038_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (600, 9, 1024), Y_shape: (600,)\n",
      "5/60 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/039_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (750, 9, 1024), Y_shape: (750,)\n",
      "6/60 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/040_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (900, 9, 1024), Y_shape: (900,)\n",
      "7/60 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/045_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (1050, 9, 1024), Y_shape: (1050,)\n",
      "8/60 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/042_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (1200, 9, 1024), Y_shape: (1200,)\n",
      "9/60 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/043_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (1350, 9, 1024), Y_shape: (1350,)\n",
      "10/60 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/044_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (1500, 9, 1024), Y_shape: (1500,)\n",
      "11/60 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/063_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (1650, 9, 1024), Y_shape: (1650,)\n",
      "12/60 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/064_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (1800, 9, 1024), Y_shape: (1800,)\n",
      "13/60 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/065_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (1950, 9, 1024), Y_shape: (1950,)\n",
      "14/60 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/062_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (2100, 9, 1024), Y_shape: (2100,)\n",
      "15/60 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/068_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (2250, 9, 1024), Y_shape: (2250,)\n",
      "16/60 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/060_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (2400, 9, 1024), Y_shape: (2400,)\n",
      "17/60 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/067_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (2550, 9, 1024), Y_shape: (2550,)\n",
      "18/60 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/066_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (2700, 9, 1024), Y_shape: (2700,)\n",
      "19/60 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/061_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (2850, 9, 1024), Y_shape: (2850,)\n",
      "20/60 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/069_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (3000, 9, 1024), Y_shape: (3000,)\n",
      "21/60 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/149_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (3150, 9, 1024), Y_shape: (3150,)\n",
      "22/60 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/154_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (3300, 9, 1024), Y_shape: (3300,)\n",
      "23/60 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/153_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (3450, 9, 1024), Y_shape: (3450,)\n",
      "24/60 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/152_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (3600, 9, 1024), Y_shape: (3600,)\n",
      "25/60 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/155_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (3750, 9, 1024), Y_shape: (3750,)\n",
      "26/60 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/157_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (3900, 9, 1024), Y_shape: (3900,)\n",
      "27/60 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/150_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (4050, 9, 1024), Y_shape: (4050,)\n",
      "28/60 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/158_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (4200, 9, 1024), Y_shape: (4200,)\n",
      "29/60 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/151_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (4350, 9, 1024), Y_shape: (4350,)\n",
      "30/60 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/156_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (4500, 9, 1024), Y_shape: (4500,)\n",
      "31/60 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/130_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (4650, 9, 1024), Y_shape: (4650,)\n",
      "32/60 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/131_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (4800, 9, 1024), Y_shape: (4800,)\n",
      "33/60 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/126_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (4950, 9, 1024), Y_shape: (4950,)\n",
      "34/60 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/133_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (5100, 9, 1024), Y_shape: (5100,)\n",
      "35/60 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/134_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (5250, 9, 1024), Y_shape: (5250,)\n",
      "36/60 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/129_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (5400, 9, 1024), Y_shape: (5400,)\n",
      "37/60 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/128_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (5550, 9, 1024), Y_shape: (5550,)\n",
      "38/60 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/135_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (5700, 9, 1024), Y_shape: (5700,)\n",
      "39/60 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/132_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (5850, 9, 1024), Y_shape: (5850,)\n",
      "40/60 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/127_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (6000, 9, 1024), Y_shape: (6000,)\n",
      "41/60 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/220_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (6150, 9, 1024), Y_shape: (6150,)\n",
      "42/60 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/227_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (6300, 9, 1024), Y_shape: (6300,)\n",
      "43/60 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/226_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (6450, 9, 1024), Y_shape: (6450,)\n",
      "44/60 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/221_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (6600, 9, 1024), Y_shape: (6600,)\n",
      "45/60 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/223_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (6750, 9, 1024), Y_shape: (6750,)\n",
      "46/60 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/224_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (6900, 9, 1024), Y_shape: (6900,)\n",
      "47/60 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/225_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (7050, 9, 1024), Y_shape: (7050,)\n",
      "48/60 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/222_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (7200, 9, 1024), Y_shape: (7200,)\n",
      "49/60 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/219_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (7350, 9, 1024), Y_shape: (7350,)\n",
      "50/60 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/218_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (7500, 9, 1024), Y_shape: (7500,)\n",
      "51/60 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/241_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (7650, 9, 1024), Y_shape: (7650,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/60 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/249_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (7800, 9, 1024), Y_shape: (7800,)\n",
      "53/60 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/246_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (7950, 9, 1024), Y_shape: (7950,)\n",
      "54/60 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/247_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (8100, 9, 1024), Y_shape: (8100,)\n",
      "55/60 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/248_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (8250, 9, 1024), Y_shape: (8250,)\n",
      "56/60 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/240_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (8400, 9, 1024), Y_shape: (8400,)\n",
      "57/60 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/242_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (8550, 9, 1024), Y_shape: (8550,)\n",
      "58/60 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/245_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (8700, 9, 1024), Y_shape: (8700,)\n",
      "59/60 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/244_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (8850, 9, 1024), Y_shape: (8850,)\n",
      "60/60 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/243_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (9000, 9, 1024), Y_shape: (9000,)\n",
      "1/60 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/478_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (150, 9, 1024), Y_shape: (150,)\n",
      "2/60 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/480_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (300, 9, 1024), Y_shape: (300,)\n",
      "3/60 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/477_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (450, 9, 1024), Y_shape: (450,)\n",
      "4/60 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/476_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (600, 9, 1024), Y_shape: (600,)\n",
      "5/60 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/481_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (750, 9, 1024), Y_shape: (750,)\n",
      "6/60 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/479_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (900, 9, 1024), Y_shape: (900,)\n",
      "7/60 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/484_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (1050, 9, 1024), Y_shape: (1050,)\n",
      "8/60 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/483_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (1200, 9, 1024), Y_shape: (1200,)\n",
      "9/60 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/482_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (1350, 9, 1024), Y_shape: (1350,)\n",
      "10/60 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/475_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (1500, 9, 1024), Y_shape: (1500,)\n",
      "11/60 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/503_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (1650, 9, 1024), Y_shape: (1650,)\n",
      "12/60 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/504_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (1800, 9, 1024), Y_shape: (1800,)\n",
      "13/60 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/505_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (1950, 9, 1024), Y_shape: (1950,)\n",
      "14/60 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/502_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (2100, 9, 1024), Y_shape: (2100,)\n",
      "15/60 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/500_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (2250, 9, 1024), Y_shape: (2250,)\n",
      "16/60 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/508_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (2400, 9, 1024), Y_shape: (2400,)\n",
      "17/60 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/507_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (2550, 9, 1024), Y_shape: (2550,)\n",
      "18/60 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/506_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (2700, 9, 1024), Y_shape: (2700,)\n",
      "19/60 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/501_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (2850, 9, 1024), Y_shape: (2850,)\n",
      "20/60 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/499_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (3000, 9, 1024), Y_shape: (3000,)\n",
      "21/60 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/423_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (3150, 9, 1024), Y_shape: (3150,)\n",
      "22/60 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/424_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (3300, 9, 1024), Y_shape: (3300,)\n",
      "23/60 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/422_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (3450, 9, 1024), Y_shape: (3450,)\n",
      "24/60 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/420_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (3600, 9, 1024), Y_shape: (3600,)\n",
      "25/60 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/421_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (3750, 9, 1024), Y_shape: (3750,)\n",
      "26/60 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/415_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (3900, 9, 1024), Y_shape: (3900,)\n",
      "27/60 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/416_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (4050, 9, 1024), Y_shape: (4050,)\n",
      "28/60 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/419_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (4200, 9, 1024), Y_shape: (4200,)\n",
      "29/60 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/418_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (4350, 9, 1024), Y_shape: (4350,)\n",
      "30/60 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/417_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (4500, 9, 1024), Y_shape: (4500,)\n",
      "31/60 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/435_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (4650, 9, 1024), Y_shape: (4650,)\n",
      "32/60 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/428_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (4800, 9, 1024), Y_shape: (4800,)\n",
      "33/60 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/427_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (4950, 9, 1024), Y_shape: (4950,)\n",
      "34/60 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/432_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (5100, 9, 1024), Y_shape: (5100,)\n",
      "35/60 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/433_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (5250, 9, 1024), Y_shape: (5250,)\n",
      "36/60 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/429_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (5400, 9, 1024), Y_shape: (5400,)\n",
      "37/60 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/434_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (5550, 9, 1024), Y_shape: (5550,)\n",
      "38/60 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/436_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (5700, 9, 1024), Y_shape: (5700,)\n",
      "39/60 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/431_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (5850, 9, 1024), Y_shape: (5850,)\n",
      "40/60 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/430_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (6000, 9, 1024), Y_shape: (6000,)\n",
      "41/60 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/290_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (6150, 9, 1024), Y_shape: (6150,)\n",
      "42/60 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/291_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (6300, 9, 1024), Y_shape: (6300,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/60 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/289_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (6450, 9, 1024), Y_shape: (6450,)\n",
      "44/60 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/294_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (6600, 9, 1024), Y_shape: (6600,)\n",
      "45/60 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/286_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (6750, 9, 1024), Y_shape: (6750,)\n",
      "46/60 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/293_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (6900, 9, 1024), Y_shape: (6900,)\n",
      "47/60 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/292_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (7050, 9, 1024), Y_shape: (7050,)\n",
      "48/60 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/287_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (7200, 9, 1024), Y_shape: (7200,)\n",
      "49/60 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/295_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (7350, 9, 1024), Y_shape: (7350,)\n",
      "50/60 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/288_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (7500, 9, 1024), Y_shape: (7500,)\n",
      "51/60 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/315_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (7650, 9, 1024), Y_shape: (7650,)\n",
      "52/60 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/312_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (7800, 9, 1024), Y_shape: (7800,)\n",
      "53/60 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/313_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (7950, 9, 1024), Y_shape: (7950,)\n",
      "54/60 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/314_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (8100, 9, 1024), Y_shape: (8100,)\n",
      "55/60 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/309_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (8250, 9, 1024), Y_shape: (8250,)\n",
      "56/60 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/316_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (8400, 9, 1024), Y_shape: (8400,)\n",
      "57/60 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/311_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (8550, 9, 1024), Y_shape: (8550,)\n",
      "58/60 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/318_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (8700, 9, 1024), Y_shape: (8700,)\n",
      "59/60 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/310_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (8850, 9, 1024), Y_shape: (8850,)\n",
      "60/60 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/317_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (9000, 9, 1024), Y_shape: (9000,)\n"
     ]
    }
   ],
   "source": [
    "window_size = 1024\n",
    "overlap_size = 0\n",
    "vel_cut_off_value = 0\n",
    "#features_of_interest = ['S:x_bottom', 'S:y_bottom', 'S:z_bottom', 'S:x_nut', 'S:y_nut', 'S:z_nut', 'S:x_top', 'S:y_top', 'S:z_top', 'S:Nominal_rotational_speed[rad/s]', 'S:Actual_rotational_speed[µm/s]', 'S:Actual_position_of_the_position_encoder(dy/dt)[µm/s]', 'S:Actual_position_of_the_motor_encoder(dy/dt)[µm/s]']\n",
    "features_of_interest = [\n",
    "    'S:x_bottom', 'S:y_bottom', 'S:z_bottom',\n",
    "    'S:x_nut', 'S:y_nut', 'S:z_nut', 'S:x_top', 'S:y_top', 'S:z_top'\n",
    "                        ]\n",
    "\n",
    "list_of_source_BSD_states = [\"2\", \"3\", \"11\", \"12\", \"20\", \"21\"]\n",
    "list_of_target_BSD_states = [\"5\", \"6\", \"14\", \"15\", \"23\", \"24\"]\n",
    "data_path = Path(os.getcwd()).parents[1]\n",
    "data_path = os.path.join(data_path, \"data\")\n",
    "dataloader_split_ce = 0.2\n",
    "dataloader_split_mmd = 0.6\n",
    "dataloader_split_val = 0.2\n",
    "batch_size = 32\n",
    "\n",
    "source_loader = Dataloader_mmd_ce.create_dataloader(data_path, list_of_source_BSD_states, window_size, overlap_size, features_of_interest, dataloader_split_ce, dataloader_split_mmd, dataloader_split_val, batch_size)\n",
    "target_loader = Dataloader_mmd_ce.create_dataloader(data_path, list_of_target_BSD_states, window_size, overlap_size, features_of_interest, dataloader_split_ce, dataloader_split_mmd, dataloader_split_val, batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size, input_fc_size, hidden_fc_size_1):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(input_size, 64, kernel_size=100, stride=1)#input: ((1024+2*0-(100-1)-1)/1)+1 = 925\n",
    "        self.pool1 = nn.MaxPool1d(4, stride=3) #((925+2*0-1*(4-1)-1)/3)+1 = 308\n",
    "        self.conv2 = nn.Conv1d(64,32,kernel_size=10, stride = 1, padding=1)#input: ((308+2*1-(10-1)-1)/1)+1 = 301\n",
    "        self.batch1 =nn.BatchNorm1d(32) #301\n",
    "        self.pool2 = nn.MaxPool1d(4, stride=3) #((301+2*0-1*(4-1)-1)/3)+1 = 100\n",
    "        self.conv3 = nn.Conv1d(32,16,kernel_size=5, stride = 1, padding=1) #((100+2*1-(5-1)-1)/1)+1 = 98\n",
    "        self.batch2 =nn.BatchNorm1d(16) #98\n",
    "        self.pool3 = nn.MaxPool1d(5, stride=3) #((98+2*0-1*(5-1)-1)/3)+1 = 32\n",
    "        self.fc1 = nn.Linear(input_fc_size, hidden_fc_size_1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_conv_1 = self.conv1(x) #conv1\n",
    "        x = F.relu(x_conv_1) #relu\n",
    "        x = self.pool1(x) #pool1\n",
    "        x_conv_2 = self.conv2(x) #conv2\n",
    "        x = self.batch1(x_conv_2) #batch1\n",
    "        x = F.relu(x) #relu\n",
    "        x = self.pool2(x) #pool2\n",
    "        x_conv_3 = self.conv3(x) #conv3\n",
    "        x = self.batch2(x_conv_3) #batch2\n",
    "        x = F.relu(x) #relu\n",
    "        x = self.pool3(x) #pool3\n",
    "        x_flatten = torch.reshape(x,(x.shape[0],x.shape[1]*x.shape[2])) #flatten\n",
    "        x_normalize = torch.nn.functional.normalize(x_flatten)\n",
    "        x_fc1 = self.fc1(x_normalize) #fc1\n",
    "        \n",
    "        return x_conv_1, x_conv_2, x_conv_3, x_flatten, x_fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, hidden_fc_size_1, hidden_fc_size_2, output_size):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc2 = nn.Linear(hidden_fc_size_1, hidden_fc_size_2)\n",
    "        self.fc3 = nn.Linear(hidden_fc_size_2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_fc2 = self.fc2(x) #fc2\n",
    "        x_fc3 = self.fc3(x_fc2) #fc3\n",
    "        \n",
    "        return x_fc2, x_fc3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv1d(9, 64, kernel_size=(100,), stride=(1,))\n",
      "  (pool1): MaxPool1d(kernel_size=4, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(64, 32, kernel_size=(10,), stride=(1,), padding=(1,))\n",
      "  (batch1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool1d(kernel_size=4, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(32, 16, kernel_size=(5,), stride=(1,), padding=(1,))\n",
      "  (batch2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool3): MaxPool1d(kernel_size=5, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=512, out_features=50, bias=True)\n",
      ")\n",
      "Classifier(\n",
      "  (fc2): Linear(in_features=50, out_features=3, bias=True)\n",
      "  (fc3): Linear(in_features=3, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = 9\n",
    "input_fc_size = 16*32\n",
    "hidden_fc_size_1 = 50\n",
    "hidden_fc_size_2 = 3\n",
    "output_size = 2\n",
    "\n",
    "model_cnn = CNN(input_size, input_fc_size, hidden_fc_size_1)\n",
    "\n",
    "model_fc = Classifier(hidden_fc_size_1, hidden_fc_size_2, output_size)\n",
    "\n",
    "print(model_cnn)\n",
    "\n",
    "print(model_fc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from mmd_loss import MMD_loss\n",
    "class MMD_loss(nn.Module):\n",
    "    def __init__(self, fix_sigma = None, kernel_mul = 2.0, kernel_num = 5):\n",
    "        super(MMD_loss, self).__init__()\n",
    "        self.kernel_num = kernel_num\n",
    "        self.kernel_mul = kernel_mul\n",
    "        self.fix_sigma = fix_sigma\n",
    "        return\n",
    "    def gaussian_kernel(self, source, target, kernel_mul=2.0, kernel_num=5, fix_sigma = None):\n",
    "        n_samples = int(source.size()[0])+int(target.size()[0])\n",
    "        total = torch.cat([source, target], dim=0)\n",
    "        \n",
    "        total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "        total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "        L2_distance = ((total0-total1)**2).sum(2) \n",
    "        kernel_val = [torch.exp(-L2_distance / sigma) for sigma in self.fix_sigma]\n",
    "        return sum(kernel_val)\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        batch_size = int(source.size()[0])\n",
    "        kernels = self.gaussian_kernel(source, target, kernel_mul=self.kernel_mul, kernel_num=self.kernel_num, fix_sigma=self.fix_sigma)\n",
    "        XX = kernels[:batch_size, :batch_size]\n",
    "        YY = kernels[batch_size:, batch_size:]\n",
    "        XY = kernels[:batch_size, batch_size:]\n",
    "        YX = kernels[batch_size:, :batch_size]\n",
    "        loss = torch.mean(XX + YY - XY -YX)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def forward(model_cnn, model_fc, data, labels_source, labels_target, criterion, MMD_loss_calculator, MMD_loss_flag_phase, GAMMA):\n",
    "    \n",
    "        #Feature extraction\n",
    "        x_conv_1, x_conv_2, x_conv_3, x_flatten, x_fc1 = model_cnn(data.float())\n",
    "        x_fc2, x_fc3 = model_fc(x_fc1)\n",
    "        \n",
    "        batch_size = len(labels_source)   \n",
    "\n",
    "        #CE Loss\n",
    "        source_ce_loss = criterion(x_fc3[:batch_size, :], labels_source)\n",
    "        target_ce_loss = criterion(x_fc3[batch_size:, :], labels_target)\n",
    "        \n",
    "        #MMD Loss\n",
    "        mmd_loss_1_fc = MMD_loss_calculator.forward(x_flatten[:batch_size, :], x_flatten[batch_size:, :])\n",
    "        mmd_loss_2_fc = MMD_loss_calculator.forward(x_fc1[:batch_size, :], x_fc1[batch_size:, :])\n",
    "        mmd_loss_3_fc = MMD_loss_calculator.forward(x_fc2[:batch_size, :], x_fc2[batch_size:, :])\n",
    "        \n",
    "        mmd_loss_1_cnn = 0\n",
    "        mmd_loss_2_cnn = 0\n",
    "        mmd_loss_3_cnn = 0\n",
    "        \n",
    "        for channel1 in range(x_conv_1.size()[1]):\n",
    "            mmd_loss_1_cnn += MMD_loss_calculator.forward(x_conv_1[:batch_size, channel1, :], x_conv_1[batch_size:,channel1, :])\n",
    "        for channel2 in range(x_conv_2.size()[1]):\n",
    "            mmd_loss_2_cnn += MMD_loss_calculator.forward(x_conv_2[:batch_size, channel2, :], x_conv_2[batch_size:,channel2, :])\n",
    "        for channel3 in range(x_conv_3.size()[1]):\n",
    "            mmd_loss_3_cnn += MMD_loss_calculator.forward(x_conv_3[:batch_size, channel3, :], x_conv_3[batch_size:,channel3, :])\n",
    "\n",
    "\n",
    "        \n",
    "        mmd_loss = mmd_loss_1_fc + mmd_loss_2_fc + mmd_loss_3_fc + mmd_loss_1_cnn + mmd_loss_2_cnn + mmd_loss_3_cnn\n",
    "\n",
    "        #collect information about labels, predictions to calculate accuracy\n",
    "        n_correct_source = 0\n",
    "        n_correct_target = 0\n",
    "        n_samples_source = 0\n",
    "        n_samples_target = 0\n",
    "\n",
    "        # list of classified latent space features in FC1\n",
    "        class_0_source_fc2 = x_fc2[:batch_size, :][labels_source==0]\n",
    "        class_1_source_fc2 = x_fc2[:batch_size, :][labels_source==1]\n",
    "        class_0_target_fc2 = x_fc2[batch_size:, :][labels_target==0]\n",
    "        class_1_target_fc2 = x_fc2[batch_size:, :][labels_target==1]\n",
    "        \n",
    "        argmax_source_pred = torch.argmax(x_fc3[:batch_size, :], dim=1)\n",
    "        result_source_pred = argmax_source_pred == labels_source\n",
    "        correct_source_pred = result_source_pred[result_source_pred == True]\n",
    "        acc_total_source = 100 * len(correct_source_pred)/len(labels_source)\n",
    "        \n",
    "        argmax_target_pred = torch.argmax(x_fc3[batch_size:, :], dim=1)\n",
    "        result_target_pred = argmax_target_pred == labels_target\n",
    "        correct_target_pred = result_target_pred[result_target_pred == True]\n",
    "        acc_total_target = 100 * len(correct_target_pred)/len(labels_target)\n",
    "        \n",
    "      \n",
    "        if MMD_loss_flag_phase == True:\n",
    "            loss = source_ce_loss# + mmd_loss\n",
    "        else:\n",
    "            loss = source_ce_loss\n",
    "\n",
    "        \n",
    "        return loss, mmd_loss, source_ce_loss, target_ce_loss, acc_total_source, acc_total_target, class_0_source_fc2, class_1_source_fc2, class_0_target_fc2, class_1_target_fc2\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_graph = SummaryWriter('runs/Dataloader2/graph')\n",
    "writer_source_val = SummaryWriter('runs/Dataloader2/source_val')\n",
    "writer_source_mmd = SummaryWriter('runs/Dataloader2/source_mmd')\n",
    "writer_source_ce = SummaryWriter('runs/Dataloader2/source_ce')\n",
    "writer_target_val = SummaryWriter('runs/Dataloader2/target_val')\n",
    "writer_target_mmd = SummaryWriter('runs/Dataloader2/target_mmd')\n",
    "writer_target_ce = SummaryWriter('runs/Dataloader2/target_ce')\n",
    "\n",
    "writer_source = {}\n",
    "writer_source[\"val\"] = writer_source_val\n",
    "writer_source[\"mmd\"] = writer_source_mmd\n",
    "writer_source[\"ce\"] = writer_source_ce\n",
    "\n",
    "writer_target = {}\n",
    "writer_target[\"val\"] = writer_target_val\n",
    "writer_target[\"mmd\"] = writer_target_mmd\n",
    "writer_target[\"ce\"] = writer_target_ce\n",
    "\n",
    "\n",
    "#define training params\n",
    "num_epochs = 10\n",
    "GAMMA = 2.5\n",
    "SIGMA = torch.tensor([1,2,4,8,16],dtype=torch.float64)\n",
    "\n",
    "#define loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "MMD_loss_calculator = MMD_loss(fix_sigma = SIGMA)\n",
    "#mmd_loss_flag\n",
    "MMD_loss_flag_phase = {}\n",
    "MMD_loss_flag_phase[\"val\"] = True\n",
    "MMD_loss_flag_phase[\"mmd\"] = True\n",
    "MMD_loss_flag_phase[\"ce\"] = False\n",
    "\n",
    "optimizer1 = torch.optim.Adam([\n",
    "{'params': model_cnn.parameters()},\n",
    "{'params': model_fc.parameters(), 'lr': 1e-4}\n",
    "], lr=1e-2, betas=(0.9, 0.999))\n",
    "\n",
    "optimizer2 = torch.optim.Adam(model_fc.parameters(), lr=1e-2, betas=(0.9, 0.999))\n",
    "\n",
    "\n",
    "#training iterations\n",
    "phases = ['val', 'mmd', 'ce']\n",
    "\n",
    "\n",
    "#init train data for each batch\n",
    "loss_collected = 0\n",
    "source_ce_loss_collected = 0\n",
    "target_ce_loss_collected = 0\n",
    "mmd_loss_collected = 0\n",
    "acc_total_source_collected = 0\n",
    "acc_total_target_collected = 0\n",
    "\n",
    "#plot lists\n",
    "mmd_loss_list = {}\n",
    "mmd_loss_list['val']=[]\n",
    "mmd_loss_list['mmd']=[]\n",
    "mmd_loss_list['ce'] = []\n",
    "\n",
    "ce_loss_list_source = {}\n",
    "ce_loss_list_source['val']=[]\n",
    "ce_loss_list_source['mmd']=[]\n",
    "ce_loss_list_source['ce'] = []\n",
    "\n",
    "ce_loss_list_target = {}\n",
    "ce_loss_list_target['val']=[]\n",
    "ce_loss_list_target['mmd']=[]\n",
    "ce_loss_list_target['ce'] = []\n",
    "\n",
    "accuracy_list_source = {}\n",
    "accuracy_list_source['val']=[]\n",
    "accuracy_list_source['mmd']=[]\n",
    "accuracy_list_source['ce'] = []\n",
    "\n",
    "accuracy_list_target = {}\n",
    "accuracy_list_target['val']=[]\n",
    "accuracy_list_target['mmd']=[]\n",
    "accuracy_list_target['ce'] = []\n",
    "\n",
    "# Train and Validate the model\n",
    "for epoch in range(num_epochs):\n",
    "    #plot mmd\n",
    "    class_0_source_fc2_collect = torch.empty((0,3))\n",
    "    class_1_source_fc2_collect = torch.empty((0,3))\n",
    "    class_0_target_fc2_collect = torch.empty((0,3))\n",
    "    class_1_target_fc2_collect = torch.empty((0,3))\n",
    "\n",
    "    \n",
    "    for phase in phases:\n",
    "        iter_loader_source = iter(source_loader[phase])\n",
    "        iter_loader_target = iter(target_loader[phase])\n",
    "        for i in range(len(iter_loader_source)):\n",
    "            \n",
    "            ########Forward pass########\n",
    "            data_source, labels_source = iter_loader_source.next() #batch_size number of windows and labels from source domain\n",
    "            data_target, labels_target = iter_loader_target.next() #batch_size number of windows from target domain\n",
    "            data = torch.cat((data_source, data_target), dim=0) #concat the windows to 2*batch_size number of windows\n",
    "            \n",
    "            \n",
    "            if phase == \"val\":\n",
    "                \n",
    "                #no training\n",
    "                model_cnn.train(False)\n",
    "                model_fc.train(False)\n",
    "                \n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    _, mmd_loss, source_ce_loss, target_ce_loss, acc_total_source, acc_total_target, class_0_source_fc2, class_1_source_fc2, class_0_target_fc2, class_1_target_fc2 = forward(model_cnn, model_fc, data, labels_source, labels_target, criterion, MMD_loss_calculator, MMD_loss_flag_phase, GAMMA)\n",
    "                    \n",
    "                    # collect latent features for plot \n",
    "                    class_0_source_fc2_collect = torch.cat((class_0_source_fc2_collect, class_0_source_fc2), 0)\n",
    "                    class_1_source_fc2_collect = torch.cat((class_1_source_fc2_collect, class_1_source_fc2), 0)\n",
    "                    class_0_target_fc2_collect = torch.cat((class_0_target_fc2_collect, class_0_target_fc2), 0)\n",
    "                    class_1_target_fc2_collect = torch.cat((class_1_target_fc2_collect, class_1_target_fc2), 0)\n",
    "\n",
    "            elif phase == \"mmd\":\n",
    "                \n",
    "                #training\n",
    "                model_cnn.train(True)\n",
    "                model_fc.train(True)\n",
    "                \n",
    "                ########Forward pass########\n",
    "                loss, mmd_loss, source_ce_loss, target_ce_loss, acc_total_source, acc_total_target, _, _, _, _ = forward(model_cnn, model_fc, data, labels_source, labels_target, criterion, MMD_loss_calculator, MMD_loss_flag_phase, GAMMA)\n",
    "                \n",
    "                mmd_loss = mmd_loss.detach()\n",
    "                source_ce_loss = source_ce_loss.detach()\n",
    "                target_ce_loss = target_ce_loss.detach()\n",
    "                ########Backward pass########\n",
    "                optimizer1.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer1.step()\n",
    "                \n",
    "            elif phase == \"ce\":\n",
    "                \n",
    "                #training\n",
    "                model_cnn.train(True)\n",
    "                model_fc.train(True)\n",
    "                \n",
    "                ########Forward pass########\n",
    "                loss, mmd_loss, source_ce_loss, target_ce_loss, acc_total_source, acc_total_target, _, _, _, _ = forward(model_cnn, model_fc, data, labels_source, labels_target, criterion, MMD_loss_calculator, MMD_loss_flag_phase, GAMMA)\n",
    "                \n",
    "                mmd_loss = mmd_loss.detach()\n",
    "                source_ce_loss = source_ce_loss.detach()\n",
    "                target_ce_loss = target_ce_loss.detach()\n",
    "                ########Backward pass########\n",
    "                optimizer2.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer2.step()\n",
    "            \n",
    "            # collect train data for each train phase\n",
    "            mmd_loss_collected += mmd_loss\n",
    "            source_ce_loss_collected += source_ce_loss\n",
    "            target_ce_loss_collected += target_ce_loss\n",
    "            acc_total_source_collected += acc_total_source\n",
    "            acc_total_target_collected += acc_total_target\n",
    "            \n",
    "            \n",
    "                \n",
    "        #plot\n",
    "        if phase == \"val\" and (epoch ==0 or epoch ==2 or epoch == 4 or epoch ==6):\n",
    "\n",
    "            fig = plt.figure()\n",
    "            plt.gcf().set_size_inches((20, 20)) \n",
    "            ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "            m = [1,2,3,4]\n",
    "            data_plot = [class_0_source_fc2_collect, class_1_source_fc2_collect, class_0_target_fc2_collect, class_1_target_fc2_collect         \n",
    "\n",
    "]\n",
    "            for i in range(4):\n",
    "                ax.scatter(data_plot[i][:,0], data_plot[i][:,1], data_plot[i][:,2], marker=m[i])\n",
    "            \n",
    "            plt.show()\n",
    "            fig.savefig(f\"no_mmd_epoch{epoch}\")            \n",
    "\n",
    "        \n",
    "        # Normalize collected train data for each train phase\n",
    "        running_mmd_loss = mmd_loss_collected / len(source_loader[phase])\n",
    "        \n",
    "        running_acc_source = acc_total_source_collected / len(source_loader[phase])\n",
    "        running_acc_target = acc_total_target_collected / len(target_loader[phase])\n",
    "        \n",
    "        running_source_ce_loss = source_ce_loss_collected / len(source_loader[phase])\n",
    "        running_target_ce_loss = target_ce_loss_collected / len(target_loader[phase])\n",
    "        \n",
    "        \n",
    "        #Add train data to plot list\n",
    "        accuracy_list_source[phase].append(running_acc_source)\n",
    "        accuracy_list_target[phase].append(running_acc_target)\n",
    "        \n",
    "        ce_loss_list_source[phase].append(running_source_ce_loss)\n",
    "        ce_loss_list_target[phase].append(running_target_ce_loss)\n",
    "        \n",
    "        mmd_loss_list[phase].append(running_mmd_loss)\n",
    "\n",
    "\n",
    "        #Add train data to tensorflow list\n",
    "        writer_source[phase].add_scalar(f'accuracy', running_acc_source, epoch)\n",
    "        writer_target[phase].add_scalar(f'accuracy', running_acc_target, epoch)\n",
    "        \n",
    "        writer_source[phase].add_scalar(f'ce_loss', running_source_ce_loss, epoch)\n",
    "        writer_target[phase].add_scalar(f'ce_loss', running_target_ce_loss, epoch)\n",
    "        \n",
    "        writer_source[phase].add_scalar(f'mmd_loss', running_mmd_loss, epoch)\n",
    "        \n",
    "\n",
    "        #reset train data for each batch\n",
    "        loss_collected = 0\n",
    "        source_ce_loss_collected = 0\n",
    "        target_ce_loss_collected = 0\n",
    "        mmd_loss_collected = 0\n",
    "        acc_total_source_collected = 0\n",
    "        acc_total_target_collected = 0\n",
    "            \n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} successfull\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "plt.title('Accuracy Source Domain')\n",
    "plt.plot(accuracy_list_source['ce'], 'bo-', label = 'CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_source['mmd'], 'ro-', label = 'MMD-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_source['val'], 'go-', label = 'Val', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig1.savefig('Accuracy Source Domain')\n",
    "\n",
    "fig2 = plt.figure()\n",
    "plt.title('Accuracy Target Domain')\n",
    "plt.plot(accuracy_list_target['ce'], 'co-', label = 'CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_target['mmd'], 'mo-', label = 'MMD-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_target['val'], 'yo-', label = 'Val', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig2.savefig('Accuracy Target Domain')\n",
    "\n",
    "fig3 = plt.figure()\n",
    "plt.title('CE-Loss Source Domain')\n",
    "plt.plot(ce_loss_list_source['ce'], 'bo-', label = 'CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_source['mmd'], 'ro-', label = 'MMD-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_source['val'], 'go-', label = 'Val', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig3.savefig('CE_Loss Source Domain')\n",
    "\n",
    "fig4 = plt.figure()\n",
    "plt.title('CE-Loss Target Domain')\n",
    "plt.plot(ce_loss_list_target['ce'], 'co-', label = 'CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_target['mmd'], 'mo-', label = 'MMD-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_target['val'], 'yo-', label = 'Val', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig4.savefig('CE_Loss Target Domain')\n",
    "\n",
    "fig5 = plt.figure()\n",
    "plt.title('MMD-Loss')\n",
    "plt.plot(mmd_loss_list['ce'], 'bo-', label = 'CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(mmd_loss_list['mmd'], 'ro-', label = 'MMD-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(mmd_loss_list['val'], 'go-', label = 'Val', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig5.savefig('MMD_Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "with torch.no_grad():\n",
    "    classes = ['BSD_11', 'BSD_21', 'BSD_31', 'BSD_P1']\n",
    "    \n",
    "    #collect information about labels, predictions\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(4)]\n",
    "    n_class_samples = [0 for i in range(4)]\n",
    "    n_class_samples_out = [0 for i in range(4)]\n",
    "    #iterate through batches in target_loader\n",
    "    for window, labels in target_loader[\"test\"]:\n",
    "        #make predictions for each batch\n",
    "        flatten_outputs = model(window.float())\n",
    "        outputs_hidden_layer = classifier_layer_1(flatten_outputs)\n",
    "        outputs = classifier_layer_2(outputs_hidden_layer)\n",
    "        #for each element in batch check if prediction is correct and collect total and correct predictions and labels\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            output = torch.argmax(outputs[i])\n",
    "            if label == output:\n",
    "                n_correct+=1\n",
    "                n_class_correct[label]+=1\n",
    "                \n",
    "            n_samples+=1\n",
    "            n_class_samples[label]+=1\n",
    "            n_class_samples_out[output]+=1\n",
    "\n",
    "    \n",
    "    #calculate total accuracy\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "    \n",
    "    #calculate class accuracy\n",
    "    for i in range(4):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_class_samples)\n",
    "print(n_class_samples_out)\n",
    "print(n_class_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{accuracy_list['val'][-1]*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
