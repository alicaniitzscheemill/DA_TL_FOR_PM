{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894233fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "import Dataloader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a9a8d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabiankolb/Documents/Universität/TUM_Master/Masterarbeit/CODE/DA_TL_FOR_PM/DOMAIN_ADAPTION/../Dataloader.py:36: UserWarning: Not all elements were covered\n",
      "  warnings.warn(\"Not all elements were covered\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/120 folders downloaded\n",
      "downloaded folder: NR01_20200317_PGS_31_BSD_31/020_2020_03_18.csv\n",
      "Shape of collected datafram: X_shape: (22, 13, 1024), Y_shape: (22,)\n",
      "2/120 folders downloaded\n",
      "downloaded folder: NR01_20200317_PGS_31_BSD_31/021_2020_03_18.csv\n",
      "Shape of collected datafram: X_shape: (44, 13, 1024), Y_shape: (44,)\n",
      "3/120 folders downloaded\n",
      "downloaded folder: NR01_20200317_PGS_31_BSD_31/023_2020_03_18.csv\n",
      "Shape of collected datafram: X_shape: (66, 13, 1024), Y_shape: (66,)\n",
      "4/120 folders downloaded\n",
      "downloaded folder: NR01_20200317_PGS_31_BSD_31/022_2020_03_18.csv\n",
      "Shape of collected datafram: X_shape: (88, 13, 1024), Y_shape: (88,)\n",
      "5/120 folders downloaded\n",
      "downloaded folder: NR01_20200317_PGS_31_BSD_31/019_2020_03_18.csv\n",
      "Shape of collected datafram: X_shape: (110, 13, 1024), Y_shape: (110,)\n",
      "6/120 folders downloaded\n",
      "downloaded folder: NR01_20200317_PGS_31_BSD_31/016_2020_03_18.csv\n",
      "Shape of collected datafram: X_shape: (132, 13, 1024), Y_shape: (132,)\n",
      "7/120 folders downloaded\n",
      "downloaded folder: NR01_20200317_PGS_31_BSD_31/017_2020_03_18.csv\n",
      "Shape of collected datafram: X_shape: (154, 13, 1024), Y_shape: (154,)\n",
      "8/120 folders downloaded\n",
      "downloaded folder: NR01_20200317_PGS_31_BSD_31/018_2020_03_18.csv\n",
      "Shape of collected datafram: X_shape: (176, 13, 1024), Y_shape: (176,)\n",
      "9/120 folders downloaded\n",
      "downloaded folder: NR01_20200317_PGS_31_BSD_31/015_2020_03_18.csv\n",
      "Shape of collected datafram: X_shape: (198, 13, 1024), Y_shape: (198,)\n",
      "10/120 folders downloaded\n",
      "downloaded folder: NR01_20200317_PGS_31_BSD_31/014_2020_03_18.csv\n",
      "Shape of collected datafram: X_shape: (220, 13, 1024), Y_shape: (220,)\n",
      "11/120 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/046_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (242, 13, 1024), Y_shape: (242,)\n",
      "12/120 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/037_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (264, 13, 1024), Y_shape: (264,)\n",
      "13/120 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/041_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (286, 13, 1024), Y_shape: (286,)\n",
      "14/120 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/038_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (308, 13, 1024), Y_shape: (308,)\n",
      "15/120 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/039_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (330, 13, 1024), Y_shape: (330,)\n",
      "16/120 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/040_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (352, 13, 1024), Y_shape: (352,)\n",
      "17/120 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/045_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (374, 13, 1024), Y_shape: (374,)\n",
      "18/120 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/042_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (396, 13, 1024), Y_shape: (396,)\n",
      "19/120 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/043_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (418, 13, 1024), Y_shape: (418,)\n",
      "20/120 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/044_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (440, 13, 1024), Y_shape: (440,)\n",
      "21/120 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/063_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (462, 13, 1024), Y_shape: (462,)\n",
      "22/120 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/064_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (484, 13, 1024), Y_shape: (484,)\n",
      "23/120 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/065_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (506, 13, 1024), Y_shape: (506,)\n",
      "24/120 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/062_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (528, 13, 1024), Y_shape: (528,)\n",
      "25/120 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/068_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (550, 13, 1024), Y_shape: (550,)\n",
      "26/120 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/060_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (572, 13, 1024), Y_shape: (572,)\n",
      "27/120 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/067_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (594, 13, 1024), Y_shape: (594,)\n",
      "28/120 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/066_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (616, 13, 1024), Y_shape: (616,)\n",
      "29/120 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/061_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (638, 13, 1024), Y_shape: (638,)\n",
      "30/120 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/069_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (660, 13, 1024), Y_shape: (660,)\n",
      "31/120 folders downloaded\n",
      "downloaded folder: NR04_20200424_PGS_31_BSD_P1/089_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (682, 13, 1024), Y_shape: (682,)\n",
      "32/120 folders downloaded\n",
      "downloaded folder: NR04_20200424_PGS_31_BSD_P1/081_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (704, 13, 1024), Y_shape: (704,)\n",
      "33/120 folders downloaded\n",
      "downloaded folder: NR04_20200424_PGS_31_BSD_P1/086_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (726, 13, 1024), Y_shape: (726,)\n",
      "34/120 folders downloaded\n",
      "downloaded folder: NR04_20200424_PGS_31_BSD_P1/087_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (748, 13, 1024), Y_shape: (748,)\n",
      "35/120 folders downloaded\n",
      "downloaded folder: NR04_20200424_PGS_31_BSD_P1/080_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (770, 13, 1024), Y_shape: (770,)\n",
      "36/120 folders downloaded\n",
      "downloaded folder: NR04_20200424_PGS_31_BSD_P1/088_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (792, 13, 1024), Y_shape: (792,)\n",
      "37/120 folders downloaded\n",
      "downloaded folder: NR04_20200424_PGS_31_BSD_P1/082_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (814, 13, 1024), Y_shape: (814,)\n",
      "38/120 folders downloaded\n",
      "downloaded folder: NR04_20200424_PGS_31_BSD_P1/085_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (836, 13, 1024), Y_shape: (836,)\n",
      "39/120 folders downloaded\n",
      "downloaded folder: NR04_20200424_PGS_31_BSD_P1/084_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (858, 13, 1024), Y_shape: (858,)\n",
      "40/120 folders downloaded\n",
      "downloaded folder: NR04_20200424_PGS_31_BSD_P1/083_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (880, 13, 1024), Y_shape: (880,)\n",
      "41/120 folders downloaded\n",
      "downloaded folder: NR10_20200502_PGS_21_BSD_31/177_2020_05_02.csv\n",
      "Shape of collected datafram: X_shape: (902, 13, 1024), Y_shape: (902,)\n",
      "42/120 folders downloaded\n",
      "downloaded folder: NR10_20200502_PGS_21_BSD_31/180_2020_05_02.csv\n",
      "Shape of collected datafram: X_shape: (924, 13, 1024), Y_shape: (924,)\n",
      "43/120 folders downloaded\n",
      "downloaded folder: NR10_20200502_PGS_21_BSD_31/178_2020_05_02.csv\n",
      "Shape of collected datafram: X_shape: (946, 13, 1024), Y_shape: (946,)\n",
      "44/120 folders downloaded\n",
      "downloaded folder: NR10_20200502_PGS_21_BSD_31/179_2020_05_02.csv\n",
      "Shape of collected datafram: X_shape: (968, 13, 1024), Y_shape: (968,)\n",
      "45/120 folders downloaded\n",
      "downloaded folder: NR10_20200502_PGS_21_BSD_31/181_2020_05_02.csv\n",
      "Shape of collected datafram: X_shape: (990, 13, 1024), Y_shape: (990,)\n",
      "46/120 folders downloaded\n",
      "downloaded folder: NR10_20200502_PGS_21_BSD_31/176_2020_05_02.csv\n",
      "Shape of collected datafram: X_shape: (1012, 13, 1024), Y_shape: (1012,)\n",
      "47/120 folders downloaded\n",
      "downloaded folder: NR10_20200502_PGS_21_BSD_31/174_2020_05_02.csv\n",
      "Shape of collected datafram: X_shape: (1034, 13, 1024), Y_shape: (1034,)\n",
      "48/120 folders downloaded\n",
      "downloaded folder: NR10_20200502_PGS_21_BSD_31/173_2020_05_02.csv\n",
      "Shape of collected datafram: X_shape: (1056, 13, 1024), Y_shape: (1056,)\n",
      "49/120 folders downloaded\n",
      "downloaded folder: NR10_20200502_PGS_21_BSD_31/172_2020_05_02.csv\n",
      "Shape of collected datafram: X_shape: (1078, 13, 1024), Y_shape: (1078,)\n",
      "50/120 folders downloaded\n",
      "downloaded folder: NR10_20200502_PGS_21_BSD_31/175_2020_05_02.csv\n",
      "Shape of collected datafram: X_shape: (1100, 13, 1024), Y_shape: (1100,)\n",
      "51/120 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/149_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1122, 13, 1024), Y_shape: (1122,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/120 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/154_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1144, 13, 1024), Y_shape: (1144,)\n",
      "53/120 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/153_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1166, 13, 1024), Y_shape: (1166,)\n",
      "54/120 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/152_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1188, 13, 1024), Y_shape: (1188,)\n",
      "55/120 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/155_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1210, 13, 1024), Y_shape: (1210,)\n",
      "56/120 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/157_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1232, 13, 1024), Y_shape: (1232,)\n",
      "57/120 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/150_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1254, 13, 1024), Y_shape: (1254,)\n",
      "58/120 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/158_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1276, 13, 1024), Y_shape: (1276,)\n",
      "59/120 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/151_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1298, 13, 1024), Y_shape: (1298,)\n",
      "60/120 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/156_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1320, 13, 1024), Y_shape: (1320,)\n",
      "61/120 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/130_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1342, 13, 1024), Y_shape: (1342,)\n",
      "62/120 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/131_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1364, 13, 1024), Y_shape: (1364,)\n",
      "63/120 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/126_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1386, 13, 1024), Y_shape: (1386,)\n",
      "64/120 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/133_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1408, 13, 1024), Y_shape: (1408,)\n",
      "65/120 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/134_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1430, 13, 1024), Y_shape: (1430,)\n",
      "66/120 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/129_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1452, 13, 1024), Y_shape: (1452,)\n",
      "67/120 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/128_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1474, 13, 1024), Y_shape: (1474,)\n",
      "68/120 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/135_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1496, 13, 1024), Y_shape: (1496,)\n",
      "69/120 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/132_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1518, 13, 1024), Y_shape: (1518,)\n",
      "70/120 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/127_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1540, 13, 1024), Y_shape: (1540,)\n",
      "71/120 folders downloaded\n",
      "downloaded folder: NR13_20200428_PGS_21_BSD_P1/106_2020_04_28.csv\n",
      "Shape of collected datafram: X_shape: (1562, 13, 1024), Y_shape: (1562,)\n",
      "72/120 folders downloaded\n",
      "downloaded folder: NR13_20200428_PGS_21_BSD_P1/109_2020_04_28.csv\n",
      "Shape of collected datafram: X_shape: (1584, 13, 1024), Y_shape: (1584,)\n",
      "73/120 folders downloaded\n",
      "downloaded folder: NR13_20200428_PGS_21_BSD_P1/108_2020_04_28.csv\n",
      "Shape of collected datafram: X_shape: (1606, 13, 1024), Y_shape: (1606,)\n",
      "74/120 folders downloaded\n",
      "downloaded folder: NR13_20200428_PGS_21_BSD_P1/107_2020_04_28.csv\n",
      "Shape of collected datafram: X_shape: (1628, 13, 1024), Y_shape: (1628,)\n",
      "75/120 folders downloaded\n",
      "downloaded folder: NR13_20200428_PGS_21_BSD_P1/112_2020_04_28.csv\n",
      "Shape of collected datafram: X_shape: (1650, 13, 1024), Y_shape: (1650,)\n",
      "76/120 folders downloaded\n",
      "downloaded folder: NR13_20200428_PGS_21_BSD_P1/105_2020_04_28.csv\n",
      "Shape of collected datafram: X_shape: (1672, 13, 1024), Y_shape: (1672,)\n",
      "77/120 folders downloaded\n",
      "downloaded folder: NR13_20200428_PGS_21_BSD_P1/110_2020_04_28.csv\n",
      "Shape of collected datafram: X_shape: (1694, 13, 1024), Y_shape: (1694,)\n",
      "78/120 folders downloaded\n",
      "downloaded folder: NR13_20200428_PGS_21_BSD_P1/103_2020_04_28.csv\n",
      "Shape of collected datafram: X_shape: (1716, 13, 1024), Y_shape: (1716,)\n",
      "79/120 folders downloaded\n",
      "downloaded folder: NR13_20200428_PGS_21_BSD_P1/111_2020_04_28.csv\n",
      "Shape of collected datafram: X_shape: (1738, 13, 1024), Y_shape: (1738,)\n",
      "80/120 folders downloaded\n",
      "downloaded folder: NR13_20200428_PGS_21_BSD_P1/104_2020_04_28.csv\n",
      "Shape of collected datafram: X_shape: (1760, 13, 1024), Y_shape: (1760,)\n",
      "81/120 folders downloaded\n",
      "downloaded folder: NR19_20200505_PGS_11_BSD_31/195_2020_05_05.csv\n",
      "Shape of collected datafram: X_shape: (1782, 13, 1024), Y_shape: (1782,)\n",
      "82/120 folders downloaded\n",
      "downloaded folder: NR19_20200505_PGS_11_BSD_31/198_2020_05_05.csv\n",
      "Shape of collected datafram: X_shape: (1804, 13, 1024), Y_shape: (1804,)\n",
      "83/120 folders downloaded\n",
      "downloaded folder: NR19_20200505_PGS_11_BSD_31/197_2020_05_05.csv\n",
      "Shape of collected datafram: X_shape: (1826, 13, 1024), Y_shape: (1826,)\n",
      "84/120 folders downloaded\n",
      "downloaded folder: NR19_20200505_PGS_11_BSD_31/196_2020_05_05.csv\n",
      "Shape of collected datafram: X_shape: (1848, 13, 1024), Y_shape: (1848,)\n",
      "85/120 folders downloaded\n",
      "downloaded folder: NR19_20200505_PGS_11_BSD_31/199_2020_05_05.csv\n",
      "Shape of collected datafram: X_shape: (1870, 13, 1024), Y_shape: (1870,)\n",
      "86/120 folders downloaded\n",
      "downloaded folder: NR19_20200505_PGS_11_BSD_31/204_2020_05_05.csv\n",
      "Shape of collected datafram: X_shape: (1892, 13, 1024), Y_shape: (1892,)\n",
      "87/120 folders downloaded\n",
      "downloaded folder: NR19_20200505_PGS_11_BSD_31/203_2020_05_05.csv\n",
      "Shape of collected datafram: X_shape: (1914, 13, 1024), Y_shape: (1914,)\n",
      "88/120 folders downloaded\n",
      "downloaded folder: NR19_20200505_PGS_11_BSD_31/202_2020_05_05.csv\n",
      "Shape of collected datafram: X_shape: (1936, 13, 1024), Y_shape: (1936,)\n",
      "89/120 folders downloaded\n",
      "downloaded folder: NR19_20200505_PGS_11_BSD_31/200_2020_05_05.csv\n",
      "Shape of collected datafram: X_shape: (1958, 13, 1024), Y_shape: (1958,)\n",
      "90/120 folders downloaded\n",
      "downloaded folder: NR19_20200505_PGS_11_BSD_31/201_2020_05_05.csv\n",
      "Shape of collected datafram: X_shape: (1980, 13, 1024), Y_shape: (1980,)\n",
      "91/120 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/220_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (2002, 13, 1024), Y_shape: (2002,)\n",
      "92/120 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/227_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (2024, 13, 1024), Y_shape: (2024,)\n",
      "93/120 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/226_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (2046, 13, 1024), Y_shape: (2046,)\n",
      "94/120 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/221_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (2068, 13, 1024), Y_shape: (2068,)\n",
      "95/120 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/223_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (2090, 13, 1024), Y_shape: (2090,)\n",
      "96/120 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/224_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (2112, 13, 1024), Y_shape: (2112,)\n",
      "97/120 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/225_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (2134, 13, 1024), Y_shape: (2134,)\n",
      "98/120 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/222_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (2156, 13, 1024), Y_shape: (2156,)\n",
      "99/120 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/219_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (2178, 13, 1024), Y_shape: (2178,)\n",
      "100/120 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/218_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (2200, 13, 1024), Y_shape: (2200,)\n",
      "101/120 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/241_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2222, 13, 1024), Y_shape: (2222,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/120 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/249_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2244, 13, 1024), Y_shape: (2244,)\n",
      "103/120 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/246_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2266, 13, 1024), Y_shape: (2266,)\n",
      "104/120 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/247_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2288, 13, 1024), Y_shape: (2288,)\n",
      "105/120 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/248_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2310, 13, 1024), Y_shape: (2310,)\n",
      "106/120 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/240_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2332, 13, 1024), Y_shape: (2332,)\n",
      "107/120 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/242_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2354, 13, 1024), Y_shape: (2354,)\n",
      "108/120 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/245_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2376, 13, 1024), Y_shape: (2376,)\n",
      "109/120 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/244_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2398, 13, 1024), Y_shape: (2398,)\n",
      "110/120 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/243_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2420, 13, 1024), Y_shape: (2420,)\n",
      "111/120 folders downloaded\n",
      "downloaded folder: NR22_20200508_PGS_11_BSD_P1/265_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2442, 13, 1024), Y_shape: (2442,)\n",
      "112/120 folders downloaded\n",
      "downloaded folder: NR22_20200508_PGS_11_BSD_P1/270_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2464, 13, 1024), Y_shape: (2464,)\n",
      "113/120 folders downloaded\n",
      "downloaded folder: NR22_20200508_PGS_11_BSD_P1/271_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2486, 13, 1024), Y_shape: (2486,)\n",
      "114/120 folders downloaded\n",
      "downloaded folder: NR22_20200508_PGS_11_BSD_P1/264_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2508, 13, 1024), Y_shape: (2508,)\n",
      "115/120 folders downloaded\n",
      "downloaded folder: NR22_20200508_PGS_11_BSD_P1/263_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2530, 13, 1024), Y_shape: (2530,)\n",
      "116/120 folders downloaded\n",
      "downloaded folder: NR22_20200508_PGS_11_BSD_P1/269_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2552, 13, 1024), Y_shape: (2552,)\n",
      "117/120 folders downloaded\n",
      "downloaded folder: NR22_20200508_PGS_11_BSD_P1/266_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2574, 13, 1024), Y_shape: (2574,)\n",
      "118/120 folders downloaded\n",
      "downloaded folder: NR22_20200508_PGS_11_BSD_P1/267_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2596, 13, 1024), Y_shape: (2596,)\n",
      "119/120 folders downloaded\n",
      "downloaded folder: NR22_20200508_PGS_11_BSD_P1/272_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2618, 13, 1024), Y_shape: (2618,)\n",
      "120/120 folders downloaded\n",
      "downloaded folder: NR22_20200508_PGS_11_BSD_P1/268_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2640, 13, 1024), Y_shape: (2640,)\n",
      "1/120 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/478_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (22, 13, 1024), Y_shape: (22,)\n",
      "2/120 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/480_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (44, 13, 1024), Y_shape: (44,)\n",
      "3/120 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/477_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (66, 13, 1024), Y_shape: (66,)\n",
      "4/120 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/476_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (88, 13, 1024), Y_shape: (88,)\n",
      "5/120 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/481_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (110, 13, 1024), Y_shape: (110,)\n",
      "6/120 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/479_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (132, 13, 1024), Y_shape: (132,)\n",
      "7/120 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/484_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (154, 13, 1024), Y_shape: (154,)\n",
      "8/120 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/483_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (176, 13, 1024), Y_shape: (176,)\n",
      "9/120 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/482_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (198, 13, 1024), Y_shape: (198,)\n",
      "10/120 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/475_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (220, 13, 1024), Y_shape: (220,)\n",
      "11/120 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/503_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (242, 13, 1024), Y_shape: (242,)\n",
      "12/120 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/504_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (264, 13, 1024), Y_shape: (264,)\n",
      "13/120 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/505_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (286, 13, 1024), Y_shape: (286,)\n",
      "14/120 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/502_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (308, 13, 1024), Y_shape: (308,)\n",
      "15/120 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/500_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (330, 13, 1024), Y_shape: (330,)\n",
      "16/120 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/508_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (352, 13, 1024), Y_shape: (352,)\n",
      "17/120 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/507_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (374, 13, 1024), Y_shape: (374,)\n",
      "18/120 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/506_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (396, 13, 1024), Y_shape: (396,)\n",
      "19/120 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/501_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (418, 13, 1024), Y_shape: (418,)\n",
      "20/120 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/499_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (440, 13, 1024), Y_shape: (440,)\n",
      "21/120 folders downloaded\n",
      "downloaded folder: NR07_20201001_PGS_31_BSD_32/493_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (462, 13, 1024), Y_shape: (462,)\n",
      "22/120 folders downloaded\n",
      "downloaded folder: NR07_20201001_PGS_31_BSD_32/494_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (484, 13, 1024), Y_shape: (484,)\n",
      "23/120 folders downloaded\n",
      "downloaded folder: NR07_20201001_PGS_31_BSD_32/489_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (506, 13, 1024), Y_shape: (506,)\n",
      "24/120 folders downloaded\n",
      "downloaded folder: NR07_20201001_PGS_31_BSD_32/488_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (528, 13, 1024), Y_shape: (528,)\n",
      "25/120 folders downloaded\n",
      "downloaded folder: NR07_20201001_PGS_31_BSD_32/495_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (550, 13, 1024), Y_shape: (550,)\n",
      "26/120 folders downloaded\n",
      "downloaded folder: NR07_20201001_PGS_31_BSD_32/487_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (572, 13, 1024), Y_shape: (572,)\n",
      "27/120 folders downloaded\n",
      "downloaded folder: NR07_20201001_PGS_31_BSD_32/492_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (594, 13, 1024), Y_shape: (594,)\n",
      "28/120 folders downloaded\n",
      "downloaded folder: NR07_20201001_PGS_31_BSD_32/490_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (616, 13, 1024), Y_shape: (616,)\n",
      "29/120 folders downloaded\n",
      "downloaded folder: NR07_20201001_PGS_31_BSD_32/496_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (638, 13, 1024), Y_shape: (638,)\n",
      "30/120 folders downloaded\n",
      "downloaded folder: NR07_20201001_PGS_31_BSD_32/491_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (660, 13, 1024), Y_shape: (660,)\n",
      "31/120 folders downloaded\n",
      "downloaded folder: NR09_20200917_PGS_31_BSD_P2/460_2020_09_17.csv\n",
      "Shape of collected datafram: X_shape: (682, 13, 1024), Y_shape: (682,)\n",
      "32/120 folders downloaded\n",
      "downloaded folder: NR09_20200917_PGS_31_BSD_P2/456_2020_09_17.csv\n",
      "Shape of collected datafram: X_shape: (704, 13, 1024), Y_shape: (704,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/120 folders downloaded\n",
      "downloaded folder: NR09_20200917_PGS_31_BSD_P2/459_2020_09_17.csv\n",
      "Shape of collected datafram: X_shape: (726, 13, 1024), Y_shape: (726,)\n",
      "34/120 folders downloaded\n",
      "downloaded folder: NR09_20200917_PGS_31_BSD_P2/451_2020_09_17.csv\n",
      "Shape of collected datafram: X_shape: (748, 13, 1024), Y_shape: (748,)\n",
      "35/120 folders downloaded\n",
      "downloaded folder: NR09_20200917_PGS_31_BSD_P2/458_2020_09_17.csv\n",
      "Shape of collected datafram: X_shape: (770, 13, 1024), Y_shape: (770,)\n",
      "36/120 folders downloaded\n",
      "downloaded folder: NR09_20200917_PGS_31_BSD_P2/457_2020_09_17.csv\n",
      "Shape of collected datafram: X_shape: (792, 13, 1024), Y_shape: (792,)\n",
      "37/120 folders downloaded\n",
      "downloaded folder: NR09_20200917_PGS_31_BSD_P2/455_2020_09_17.csv\n",
      "Shape of collected datafram: X_shape: (814, 13, 1024), Y_shape: (814,)\n",
      "38/120 folders downloaded\n",
      "downloaded folder: NR09_20200917_PGS_31_BSD_P2/452_2020_09_17.csv\n",
      "Shape of collected datafram: X_shape: (836, 13, 1024), Y_shape: (836,)\n",
      "39/120 folders downloaded\n",
      "downloaded folder: NR09_20200917_PGS_31_BSD_P2/453_2020_09_17.csv\n",
      "Shape of collected datafram: X_shape: (858, 13, 1024), Y_shape: (858,)\n",
      "40/120 folders downloaded\n",
      "downloaded folder: NR09_20200917_PGS_31_BSD_P2/454_2020_09_17.csv\n",
      "Shape of collected datafram: X_shape: (880, 13, 1024), Y_shape: (880,)\n",
      "41/120 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/423_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (902, 13, 1024), Y_shape: (902,)\n",
      "42/120 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/424_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (924, 13, 1024), Y_shape: (924,)\n",
      "43/120 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/422_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (946, 13, 1024), Y_shape: (946,)\n",
      "44/120 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/420_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (968, 13, 1024), Y_shape: (968,)\n",
      "45/120 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/421_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (990, 13, 1024), Y_shape: (990,)\n",
      "46/120 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/415_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (1012, 13, 1024), Y_shape: (1012,)\n",
      "47/120 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/416_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (1034, 13, 1024), Y_shape: (1034,)\n",
      "48/120 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/419_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (1056, 13, 1024), Y_shape: (1056,)\n",
      "49/120 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/418_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (1078, 13, 1024), Y_shape: (1078,)\n",
      "50/120 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/417_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (1100, 13, 1024), Y_shape: (1100,)\n",
      "51/120 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/435_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (1122, 13, 1024), Y_shape: (1122,)\n",
      "52/120 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/428_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (1144, 13, 1024), Y_shape: (1144,)\n",
      "53/120 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/427_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (1166, 13, 1024), Y_shape: (1166,)\n",
      "54/120 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/432_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (1188, 13, 1024), Y_shape: (1188,)\n",
      "55/120 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/433_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (1210, 13, 1024), Y_shape: (1210,)\n",
      "56/120 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/429_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (1232, 13, 1024), Y_shape: (1232,)\n",
      "57/120 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/434_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (1254, 13, 1024), Y_shape: (1254,)\n",
      "58/120 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/436_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (1276, 13, 1024), Y_shape: (1276,)\n",
      "59/120 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/431_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (1298, 13, 1024), Y_shape: (1298,)\n",
      "60/120 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/430_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (1320, 13, 1024), Y_shape: (1320,)\n",
      "61/120 folders downloaded\n",
      "downloaded folder: NR16_20200908_PGS_21_BSD_32/447_2020_09_08.csv\n",
      "Shape of collected datafram: X_shape: (1342, 13, 1024), Y_shape: (1342,)\n",
      "62/120 folders downloaded\n",
      "downloaded folder: NR16_20200908_PGS_21_BSD_32/448_2020_09_08.csv\n",
      "Shape of collected datafram: X_shape: (1364, 13, 1024), Y_shape: (1364,)\n",
      "63/120 folders downloaded\n",
      "downloaded folder: NR16_20200908_PGS_21_BSD_32/439_2020_09_08.csv\n",
      "Shape of collected datafram: X_shape: (1386, 13, 1024), Y_shape: (1386,)\n",
      "64/120 folders downloaded\n",
      "downloaded folder: NR16_20200908_PGS_21_BSD_32/440_2020_09_08.csv\n",
      "Shape of collected datafram: X_shape: (1408, 13, 1024), Y_shape: (1408,)\n",
      "65/120 folders downloaded\n",
      "downloaded folder: NR16_20200908_PGS_21_BSD_32/441_2020_09_08.csv\n",
      "Shape of collected datafram: X_shape: (1430, 13, 1024), Y_shape: (1430,)\n",
      "66/120 folders downloaded\n",
      "downloaded folder: NR16_20200908_PGS_21_BSD_32/446_2020_09_08.csv\n",
      "Shape of collected datafram: X_shape: (1452, 13, 1024), Y_shape: (1452,)\n",
      "67/120 folders downloaded\n",
      "downloaded folder: NR16_20200908_PGS_21_BSD_32/444_2020_09_08.csv\n",
      "Shape of collected datafram: X_shape: (1474, 13, 1024), Y_shape: (1474,)\n",
      "68/120 folders downloaded\n",
      "downloaded folder: NR16_20200908_PGS_21_BSD_32/443_2020_09_08.csv\n",
      "Shape of collected datafram: X_shape: (1496, 13, 1024), Y_shape: (1496,)\n",
      "69/120 folders downloaded\n",
      "downloaded folder: NR16_20200908_PGS_21_BSD_32/442_2020_09_08.csv\n",
      "Shape of collected datafram: X_shape: (1518, 13, 1024), Y_shape: (1518,)\n",
      "70/120 folders downloaded\n",
      "downloaded folder: NR16_20200908_PGS_21_BSD_32/445_2020_09_08.csv\n",
      "Shape of collected datafram: X_shape: (1540, 13, 1024), Y_shape: (1540,)\n",
      "71/120 folders downloaded\n",
      "downloaded folder: NR18_20200714_PGS_21_BSD_P2/400_2020_07_14.csv\n",
      "Shape of collected datafram: X_shape: (1562, 13, 1024), Y_shape: (1562,)\n",
      "72/120 folders downloaded\n",
      "downloaded folder: NR18_20200714_PGS_21_BSD_P2/394_2020_07_14.csv\n",
      "Shape of collected datafram: X_shape: (1584, 13, 1024), Y_shape: (1584,)\n",
      "73/120 folders downloaded\n",
      "downloaded folder: NR18_20200714_PGS_21_BSD_P2/393_2020_07_14.csv\n",
      "Shape of collected datafram: X_shape: (1606, 13, 1024), Y_shape: (1606,)\n",
      "74/120 folders downloaded\n",
      "downloaded folder: NR18_20200714_PGS_21_BSD_P2/392_2020_07_14.csv\n",
      "Shape of collected datafram: X_shape: (1628, 13, 1024), Y_shape: (1628,)\n",
      "75/120 folders downloaded\n",
      "downloaded folder: NR18_20200714_PGS_21_BSD_P2/395_2020_07_14.csv\n",
      "Shape of collected datafram: X_shape: (1650, 13, 1024), Y_shape: (1650,)\n",
      "76/120 folders downloaded\n",
      "downloaded folder: NR18_20200714_PGS_21_BSD_P2/397_2020_07_14.csv\n",
      "Shape of collected datafram: X_shape: (1672, 13, 1024), Y_shape: (1672,)\n",
      "77/120 folders downloaded\n",
      "downloaded folder: NR18_20200714_PGS_21_BSD_P2/398_2020_07_14.csv\n",
      "Shape of collected datafram: X_shape: (1694, 13, 1024), Y_shape: (1694,)\n",
      "78/120 folders downloaded\n",
      "downloaded folder: NR18_20200714_PGS_21_BSD_P2/391_2020_07_14.csv\n",
      "Shape of collected datafram: X_shape: (1716, 13, 1024), Y_shape: (1716,)\n",
      "79/120 folders downloaded\n",
      "downloaded folder: NR18_20200714_PGS_21_BSD_P2/399_2020_07_14.csv\n",
      "Shape of collected datafram: X_shape: (1738, 13, 1024), Y_shape: (1738,)\n",
      "80/120 folders downloaded\n",
      "downloaded folder: NR18_20200714_PGS_21_BSD_P2/396_2020_07_14.csv\n",
      "Shape of collected datafram: X_shape: (1760, 13, 1024), Y_shape: (1760,)\n",
      "81/120 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/290_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (1782, 13, 1024), Y_shape: (1782,)\n",
      "82/120 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/291_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (1804, 13, 1024), Y_shape: (1804,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/120 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/289_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (1826, 13, 1024), Y_shape: (1826,)\n",
      "84/120 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/294_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (1848, 13, 1024), Y_shape: (1848,)\n",
      "85/120 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/286_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (1870, 13, 1024), Y_shape: (1870,)\n",
      "86/120 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/293_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (1892, 13, 1024), Y_shape: (1892,)\n",
      "87/120 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/292_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (1914, 13, 1024), Y_shape: (1914,)\n",
      "88/120 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/287_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (1936, 13, 1024), Y_shape: (1936,)\n",
      "89/120 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/295_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (1958, 13, 1024), Y_shape: (1958,)\n",
      "90/120 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/288_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (1980, 13, 1024), Y_shape: (1980,)\n",
      "91/120 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/315_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2002, 13, 1024), Y_shape: (2002,)\n",
      "92/120 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/312_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2024, 13, 1024), Y_shape: (2024,)\n",
      "93/120 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/313_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2046, 13, 1024), Y_shape: (2046,)\n",
      "94/120 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/314_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2068, 13, 1024), Y_shape: (2068,)\n",
      "95/120 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/309_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2090, 13, 1024), Y_shape: (2090,)\n",
      "96/120 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/316_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2112, 13, 1024), Y_shape: (2112,)\n",
      "97/120 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/311_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2134, 13, 1024), Y_shape: (2134,)\n",
      "98/120 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/318_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2156, 13, 1024), Y_shape: (2156,)\n",
      "99/120 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/310_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2178, 13, 1024), Y_shape: (2178,)\n",
      "100/120 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/317_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2200, 13, 1024), Y_shape: (2200,)\n",
      "101/120 folders downloaded\n",
      "downloaded folder: NR25_20200512_PGS_11_BSD_32/336_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2222, 13, 1024), Y_shape: (2222,)\n",
      "102/120 folders downloaded\n",
      "downloaded folder: NR25_20200512_PGS_11_BSD_32/339_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2244, 13, 1024), Y_shape: (2244,)\n",
      "103/120 folders downloaded\n",
      "downloaded folder: NR25_20200512_PGS_11_BSD_32/340_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2266, 13, 1024), Y_shape: (2266,)\n",
      "104/120 folders downloaded\n",
      "downloaded folder: NR25_20200512_PGS_11_BSD_32/341_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2288, 13, 1024), Y_shape: (2288,)\n",
      "105/120 folders downloaded\n",
      "downloaded folder: NR25_20200512_PGS_11_BSD_32/338_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2310, 13, 1024), Y_shape: (2310,)\n",
      "106/120 folders downloaded\n",
      "downloaded folder: NR25_20200512_PGS_11_BSD_32/337_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2332, 13, 1024), Y_shape: (2332,)\n",
      "107/120 folders downloaded\n",
      "downloaded folder: NR25_20200512_PGS_11_BSD_32/335_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2354, 13, 1024), Y_shape: (2354,)\n",
      "108/120 folders downloaded\n",
      "downloaded folder: NR25_20200512_PGS_11_BSD_32/332_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2376, 13, 1024), Y_shape: (2376,)\n",
      "109/120 folders downloaded\n",
      "downloaded folder: NR25_20200512_PGS_11_BSD_32/333_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2398, 13, 1024), Y_shape: (2398,)\n",
      "110/120 folders downloaded\n",
      "downloaded folder: NR25_20200512_PGS_11_BSD_32/334_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2420, 13, 1024), Y_shape: (2420,)\n",
      "111/120 folders downloaded\n",
      "downloaded folder: NR27_20200513_PGS_11_BSD_P2/379_2020_05_13.csv\n",
      "Shape of collected datafram: X_shape: (2442, 13, 1024), Y_shape: (2442,)\n",
      "112/120 folders downloaded\n",
      "downloaded folder: NR27_20200513_PGS_11_BSD_P2/386_2020_05_13.csv\n",
      "Shape of collected datafram: X_shape: (2464, 13, 1024), Y_shape: (2464,)\n",
      "113/120 folders downloaded\n",
      "downloaded folder: NR27_20200513_PGS_11_BSD_P2/381_2020_05_13.csv\n",
      "Shape of collected datafram: X_shape: (2486, 13, 1024), Y_shape: (2486,)\n",
      "114/120 folders downloaded\n",
      "downloaded folder: NR27_20200513_PGS_11_BSD_P2/380_2020_05_13.csv\n",
      "Shape of collected datafram: X_shape: (2508, 13, 1024), Y_shape: (2508,)\n",
      "115/120 folders downloaded\n",
      "downloaded folder: NR27_20200513_PGS_11_BSD_P2/378_2020_05_13.csv\n",
      "Shape of collected datafram: X_shape: (2530, 13, 1024), Y_shape: (2530,)\n",
      "116/120 folders downloaded\n",
      "downloaded folder: NR27_20200513_PGS_11_BSD_P2/387_2020_05_13.csv\n",
      "Shape of collected datafram: X_shape: (2552, 13, 1024), Y_shape: (2552,)\n",
      "117/120 folders downloaded\n",
      "downloaded folder: NR27_20200513_PGS_11_BSD_P2/385_2020_05_13.csv\n",
      "Shape of collected datafram: X_shape: (2574, 13, 1024), Y_shape: (2574,)\n",
      "118/120 folders downloaded\n",
      "downloaded folder: NR27_20200513_PGS_11_BSD_P2/382_2020_05_13.csv\n",
      "Shape of collected datafram: X_shape: (2596, 13, 1024), Y_shape: (2596,)\n",
      "119/120 folders downloaded\n",
      "downloaded folder: NR27_20200513_PGS_11_BSD_P2/383_2020_05_13.csv\n",
      "Shape of collected datafram: X_shape: (2618, 13, 1024), Y_shape: (2618,)\n",
      "120/120 folders downloaded\n",
      "downloaded folder: NR27_20200513_PGS_11_BSD_P2/384_2020_05_13.csv\n",
      "Shape of collected datafram: X_shape: (2640, 13, 1024), Y_shape: (2640,)\n"
     ]
    }
   ],
   "source": [
    "window_size = 1024\n",
    "overlap_size = 300\n",
    "features_of_interest = ['S:x_bottom', 'S:y_bottom', 'S:z_bottom', 'S:x_nut', 'S:y_nut', 'S:z_nut', 'S:x_top', 'S:y_top', 'S:z_top', 'S:Nominal_rotational_speed[rad/s]', 'S:Actual_rotational_speed[µm/s]', 'S:Actual_position_of_the_position_encoder(dy/dt)[µm/s]', 'S:Actual_position_of_the_motor_encoder(dy/dt)[µm/s]']\n",
    "list_of_train_BSD_states = [\"1\", \"2\", \"3\", \"4\", \"10\", \"11\", \"12\", \"13\", \"19\", \"20\", \"21\", \"22\"]\n",
    "list_of_test_BSD_states = [\"5\", \"6\", \"7\", \"9\", \"14\", \"15\", \"16\", \"18\", \"23\", \"24\", \"25\", \"27\"]\n",
    "data_path = Path(os.getcwd()).parents[1]\n",
    "data_path = os.path.join(data_path, \"data\")\n",
    "dataloader_split = 0.8\n",
    "batch_size = 4\n",
    "\n",
    "train_loader = Dataloader.create_dataloader(data_path, list_of_train_BSD_states, window_size, overlap_size, features_of_interest, \"train\", dataloader_split, batch_size)\n",
    "test_loader = Dataloader.create_dataloader(data_path, list_of_test_BSD_states, window_size, overlap_size, features_of_interest, \"test\", dataloader_split, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3620e828",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        \"\"\"\n",
    "        formula [(W−K+2P)/S]+1.\n",
    "        \"\"\"\n",
    "        self.conv1 = nn.Conv1d(input_size, 64, kernel_size=100, stride=1)#input: 1024\n",
    "        self.conv2 = nn.Conv1d(64,32,kernel_size=10, stride = 1, padding=1)#input: [(1024-100+2*0)/1]+1 = 925\n",
    "        self.batch1 =nn.BatchNorm1d(32)#input: [(925-10+2*1)/1]+1 = 918\n",
    "        self.conv3 = nn.Conv1d(32,32,kernel_size=5, stride = 1, padding=1) #input:918\n",
    "        self.batch2 =nn.BatchNorm1d(32)#input: [(918-5+2*1)/1]+1 = 916\n",
    "        self.fc1 = nn.Linear(32*916, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.selu(self.conv1(x)) #conv1\n",
    "        x = self.conv2(x) #conv2\n",
    "        x = F.selu(self.batch1(x)) #batch1\n",
    "        x = self.conv3(x) #conv3\n",
    "        x = F.selu(self.batch2(x)) #batch2\n",
    "        x = torch.reshape(x,(x.shape[0],x.shape[1]*x.shape[2])) #flatten\n",
    "        #x = self.fc1(x) #linear1\n",
    "        output = x\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e2db8572",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 13\n",
    "output_size = 4\n",
    "input_fc_size = 32*916\n",
    "\n",
    "# class residual layer: two fully connected layers\n",
    "\n",
    "residual_fc1 = nn.Linear(input_fc_size, input_fc_size)\n",
    "residual_bn1 = nn.BatchNorm1d(input_fc_size)\n",
    "residual_fc2 = nn.Linear(input_fc_size, 128)\n",
    "residual_bn2 = nn.BatchNorm1d(128)\n",
    "residual_fc3 = nn.Linear(128, input_fc_size)\n",
    "residual_fc1.weight.data.normal_(0, 0.005)\n",
    "residual_fc1.bias.data.fill_(0.1)\n",
    "residual_fc2.weight.data.normal_(0, 0.005)\n",
    "residual_fc2.bias.data.fill_(0.1)\n",
    "residual_fc3.weight.data.normal_(0, 0.005)\n",
    "residual_fc3.bias.data.fill_(0.1)\n",
    "feature_residual_layer = nn.Sequential(residual_fc2, nn.ReLU(), residual_fc3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a2cee61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_layer = nn.Linear(input_fc_size, output_size)\n",
    "classifier_layer.weight.data.normal_(0, 0.01)\n",
    "classifier_layer.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a3a26309",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_fc22 = nn.Linear(output_size, output_size)\n",
    "residual_bn22 = nn.BatchNorm1d(output_size)\n",
    "residual_fc23 = nn.Linear(output_size, output_size)\n",
    "residual_fc22.weight.data.normal_(0, 0.005)\n",
    "residual_fc22.bias.data.fill_(0.1)\n",
    "residual_fc23.weight.data.normal_(0, 0.005)\n",
    "residual_fc23.bias.data.fill_(0.1)\n",
    "class_residual_layer = nn.Sequential(residual_fc22, nn.ReLU(), residual_fc23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9a7af8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_layer = nn.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3523ec86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv1d(13, 64, kernel_size=(100,), stride=(1,))\n",
      "  (conv2): Conv1d(64, 32, kernel_size=(10,), stride=(1,), padding=(1,))\n",
      "  (batch1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(1,))\n",
      "  (batch2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=29312, out_features=4, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=29312, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=29312, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n",
      "Linear(in_features=29312, out_features=4, bias=True)\n",
      "Softmax(dim=None)\n"
     ]
    }
   ],
   "source": [
    "model = CNN(input_size, output_size)\n",
    "print(model)\n",
    "print(feature_residual_layer)\n",
    "print(class_residual_layer)\n",
    "print(classifier_layer)\n",
    "print(softmax_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "0d849c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EntropyLoss(prediction):\n",
    "    \"\"\"\n",
    "    Entropy is a measure of impurity. In classification purity is prefered, because the more distinguishable \n",
    "    4 classes are, the more reliable the classification will be. In this sense the impurity of the prediction on\n",
    "    the unlabeled targer domain is included in the loss \n",
    "    \n",
    "    INPUT:\n",
    "    @ prediction: model prediction for unlabeled target domain\n",
    "    \"\"\"\n",
    "    \n",
    "    mask = prediction.ge(0.0000001)\n",
    "    mask_out = torch.masked_select(prediction, mask)\n",
    "    entropy = - (torch.sum(mask_out * torch.log(mask_out)))\n",
    "    return entropy / float(prediction.size(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "8efdc79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guassian_kernel(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    n_samples = int(source.size()[0]) + int(target.size()[0])\n",
    "    total = torch.cat([source, target], dim=0)\n",
    "    \n",
    "    #unsqueeze 2d array of shape (8,32*916) to shape (1,8,32*916)\n",
    "    #expand to shape (8,8,32*916) by copying 2d array of shape (8,32*916) 8 times in frist dimension of 3d array\n",
    "    total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "    \n",
    "    #unsqueeze 2d array of shape (8,32*916) to shape (8,1,32*916)\n",
    "    #expand to shape (8,8,32*916) by copying each row from 2d array of shape (8,32*916) 8 times to a 2d array of shape (8,32*916). Doing that for each row and concatenating the resulting 2d arrays of shape shape (8,32*916) in the first dimension of a 3d array of shape shape (8,8,32*916)\n",
    "    total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "    \n",
    "    #L2 Norm: for nominator of exp\n",
    "    #difference between all possible elements in between and within source and target domain\n",
    "    #feature difference between two elements are summed up to one value\n",
    "    L2_distance = ((total0 - total1) ** 2).sum(2)\n",
    "    \n",
    "    #Bandwith: for denominator of exp\n",
    "    #Bandwith selection has crucial effect on estimate.\n",
    "        #small bandwith: undersmoothed since it contains too many spurious data artifacts\n",
    "        #big bandwith: oversmoothed since it obscures much of the underlying structure\n",
    "    if fix_sigma:\n",
    "        bandwidth = fix_sigma\n",
    "    else:\n",
    "        \n",
    "        #total difference/ n_samples **2 -n_samples\n",
    "        bandwidth = torch.sum(L2_distance.data) / (n_samples ** 2 - n_samples)\n",
    "    bandwidth /= kernel_mul ** (kernel_num // 2)\n",
    "    bandwidth_list = [bandwidth * (kernel_mul ** i) for i in range(kernel_num)]\n",
    "    kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n",
    "    return sum(kernel_val)  # /len(kernel_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "751371e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMD(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    batch_size = int(source.size()[0])\n",
    "    kernels = guassian_kernel(source, target,\n",
    "                              kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n",
    "    loss = 0\n",
    "    for i in range(batch_size):\n",
    "        s1, s2 = i, (i + 1) % batch_size\n",
    "        t1, t2 = s1 + batch_size, s2 + batch_size\n",
    "        loss += kernels[s1, s2] + kernels[t1, t2]\n",
    "        loss -= kernels[s1, t2] + kernels[s2, t1]\n",
    "    return loss / float(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "05b7bb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rg/g_9b4q1j0h94scy_c8tdgd980000gn/T/ipykernel_1892/1985733582.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha_off\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtransfer_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta_off\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mentropy_loss\u001b[0m \u001b[0;31m#add up losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "writer_graph = SummaryWriter('runs/Dataloader2/graph')\n",
    "writer_train = SummaryWriter('runs/Dataloader2/train')\n",
    "\n",
    "\n",
    "#define training params\n",
    "num_epochs = 50\n",
    "learning_rate = 0.008\n",
    "len_data_loader = len(train_loader[\"train\"])\n",
    "\n",
    "#define loss parameter\n",
    "loss_collected = 0\n",
    "alpha_off = 1.5\n",
    "beta_off = 0.1\n",
    "\n",
    "#define loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train and Validate the model\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_train_loader = iter(train_loader[\"train\"]) #generate new iter element for each epoch\n",
    "    epoch_test_loader = iter(test_loader)\n",
    "    for i in range(len_data_loader):\n",
    "\n",
    "        windows_source, labels_source = epoch_train_loader.next() #batch_size number of windows and labels from source domain\n",
    "        windows_target, _ = epoch_test_loader.next() #batch_size number of windows from target domain\n",
    "        \n",
    "        batch_size = len(labels_source) #take length of shorter dataoader which is the one from source domain (reason:train, val split)\n",
    "        windows = torch.cat((windows_source, windows_target), dim=0) #concat the windows to 2*batch_size number of windows\n",
    "    \n",
    "        ########Forward pass########\n",
    "        \n",
    "        #Domain Conditioned Channel Attention#\n",
    "        features_base = model(windows.float()) # Convolutional Feature extractor\n",
    "        features_residual = feature_residual_layer(features_base) # attention module\n",
    "        total_feature_residual = features_base + features_residual #apply attention module\n",
    "        output_base = classifier_layer(features_base) #Fully Connected Classifier Layer\n",
    "        \n",
    "\n",
    "        #collect loss\n",
    "        classifier_loss = criterion(output_base[:batch_size, :], labels_source) #Loss just for source domain since we do just have labels there\n",
    "        loss_collected += classifier_loss\n",
    "        \n",
    "        #Domain Conditioned Feature Correction#\n",
    "        residual_output_base = classifier_layer(total_feature_residual) #Fully Connected Classifier Layer after appleid attention module \n",
    "        output_residual = class_residual_layer(residual_output_base) #feature correction module\n",
    "        total_output_residual = residual_output_base + output_residual #apply feature correction module\n",
    "        softmax_output_base = softmax_layer(output_base) #activation of class_num output for entropy loss\n",
    "        total_softmax_residual = softmax_layer(total_output_residual)\n",
    "        entropy_loss = EntropyLoss(total_softmax_residual[batch_size:, :]) #entropy loss for all unlabeled target elements\n",
    "        \n",
    "        \n",
    "        # alignment of L task-specific feature layers (Here, we have one layer)\n",
    "        transfer_loss = MMD(features_base[:batch_size, :],\n",
    "                            total_feature_residual[batch_size:, :]) #apply MMD between CNN feature extractor and attention module output just for unlabeled target elements\n",
    "        # alignment of softmax layer\n",
    "        transfer_loss += MMD(softmax_output_base[:batch_size, :],\n",
    "                             total_softmax_residual[batch_size:, :],\n",
    "                             kernel_num=1, fix_sigma=1.68) #apply MMD between fully connected layer and feature correction module output just for unlabeled target elements\n",
    "\n",
    "        ########Backward pass########\n",
    "        optimizer.zero_grad()\n",
    "        total_loss = classifier_loss + alpha_off * transfer_loss + beta_off * entropy_loss #add up losses\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    ############## TENSORBOARD ########################\n",
    "    running_loss = loss_collected / len_data_loader\n",
    "    loss_collected = 0\n",
    "    writer_train.add_scalar(f'training loss', running_loss, epoch)\n",
    "    \n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} successfull\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e004a1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 25.492424242424242 %\n",
      "Accuracy of BSD_11: 0.0 %\n",
      "Accuracy of BSD_21: 23.484848484848484 %\n",
      "Accuracy of BSD_31: 26.96969696969697 %\n",
      "Accuracy of BSD_P1: 51.515151515151516 %\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "with torch.no_grad():\n",
    "    classes = ['BSD_11', 'BSD_21', 'BSD_31', 'BSD_P1']\n",
    "    \n",
    "    #collect information about labels, predictions\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(4)]\n",
    "    n_class_samples = [0 for i in range(4)]\n",
    "    n_class_samples_out = [0 for i in range(4)]\n",
    "    \n",
    "    #iterate through bateches in test_loader\n",
    "    for window, labels in test_loader:\n",
    "        #make predictions for each batch\n",
    "        features_base = model(window.float())\n",
    "        outputs = classifier_layer(features_base)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Domain Conditioned Channel Attention#\n",
    "        features_base = model(windows.float()) # Convolutional Feature extractor\n",
    "        features_residual = feature_residual_layer(features_base) # attention module\n",
    "        total_feature_residual = features_base + features_residual #apply attention module\n",
    "        output_base = classifier_layer(features_base) #Fully Connected Classifier Layer\n",
    "        \n",
    "        #Domain Conditioned Feature Correction#\n",
    "        residual_output_base = classifier_layer(total_feature_residual) #Fully Connected Classifier Layer after appleid attention module \n",
    "        output_residual = class_residual_layer(residual_output_base) #feature correction module\n",
    "        total_output_residual = residual_output_base + output_residual #apply feature correction module\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #for each element in batch check if prediction is correct and collect total and correct predictions and labels\n",
    "        for i in range(batch_size):\n",
    "            if len(labels)==4:\n",
    "                label = labels[i]\n",
    "                output = torch.argmax(total_output_residual[i])\n",
    "                if label == output:\n",
    "                    n_correct+=1\n",
    "                    n_class_correct[label]+=1\n",
    "                \n",
    "                n_samples+=1\n",
    "                n_class_samples[label]+=1\n",
    "                n_class_samples_out[output]+=1\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    #calculate total accuracy\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "    \n",
    "    #calculate class accuracy\n",
    "    for i in range(4):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6712b665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:105: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of BSD_11: 0.0 %\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rg/g_9b4q1j0h94scy_c8tdgd980000gn/T/ipykernel_1892/208969843.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;31m#calculate class accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_class_correct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_class_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Accuracy of {classes[i]}: {acc} %'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "writer_train = SummaryWriter('runs/Dataloader2/train')\n",
    "writer_test = SummaryWriter('runs/Dataloader2/test')\n",
    "\n",
    "writer = {}\n",
    "writer[\"train\"] = writer_train\n",
    "writer[\"test\"] = writer_test\n",
    "\n",
    "\n",
    "#define training params\n",
    "num_epochs = 50\n",
    "learning_rate = 0.008\n",
    "len_data_loader = {}\n",
    "len_data_loader[\"train\"] = len(train_loader[\"train\"])\n",
    "len_data_loader[\"test\"] = len(test_loader)\n",
    "\n",
    "\n",
    "#define loss parameter\n",
    "total_loss_collected = 0\n",
    "alpha_off = 1.5\n",
    "beta_off = 0.1\n",
    "\n",
    "#define loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#collect accuracy for each batch\n",
    "accuracy_list={}\n",
    "accuracy_list['train']=[]\n",
    "accuracy_list['test']=[]\n",
    "\n",
    "#collect loss for each batch\n",
    "loss_collected = 0\n",
    "loss_list = {}\n",
    "loss_list['train']=[]\n",
    "loss_list['test']=[]\n",
    "\n",
    "    \n",
    "#collect information about labels, predictions\n",
    "n_correct = 0\n",
    "n_samples = 0\n",
    "n_class_correct = [0 for i in range(4)]\n",
    "n_class_samples = [0 for i in range(4)]\n",
    "n_class_samples_out = [0 for i in range(4)]\n",
    "\n",
    "# Train and Validate the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train(True)\n",
    "    feature_residual_layer.train(True)\n",
    "    classifier_layer.train(True)\n",
    "    class_residual_layer.train(True)\n",
    "    \n",
    "    epoch_train_loader = iter(train_loader[\"train\"]) #generate new iter element for each epoch\n",
    "    epoch_test_loader = iter(test_loader)\n",
    "    for i in range(len_data_loader[\"train\"]):\n",
    "\n",
    "        windows_source, labels_source = epoch_train_loader.next() #batch_size number of windows and labels from source domain\n",
    "        windows_target, _ = epoch_test_loader.next() #batch_size number of windows from target domain\n",
    "        \n",
    "        batch_size = len(labels_source) #take length of shorter dataoader which is the one from source domain (reason:train, val split)\n",
    "        windows = torch.cat((windows_source, windows_target), dim=0) #concat the windows to 2*batch_size number of windows\n",
    "    \n",
    "        ########Forward pass########\n",
    "        \n",
    "        #Domain Conditioned Channel Attention#\n",
    "        features_base = model(windows.float()) # Convolutional Feature extractor\n",
    "        features_residual = feature_residual_layer(features_base) # attention module\n",
    "        total_feature_residual = features_base + features_residual #apply attention module\n",
    "        output_base = classifier_layer(features_base) #Fully Connected Classifier Layer\n",
    "                    \n",
    "        #for each element in batch check if prediction is correct and collect total and correct predictions and labels\n",
    "        for i in range(batch_size):\n",
    "            if len(labels)==4:\n",
    "                label = labels[i]\n",
    "                output = torch.argmax(output_base[i])\n",
    "                if label == output:\n",
    "                    n_correct+=1\n",
    "                    n_class_correct[label]+=1\n",
    "\n",
    "                n_samples+=1\n",
    "                n_class_samples[label]+=1\n",
    "                n_class_samples_out[output]+=1\n",
    "            else:\n",
    "                break\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        writer['train'].add_scalar(f'accuracy', acc, epoch)\n",
    "        accuracy_list['train'].append(acc)\n",
    "        \n",
    "        #reset information about labels, predictions\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        n_class_correct = [0 for i in range(4)]\n",
    "        n_class_samples = [0 for i in range(4)]\n",
    "        n_class_samples_out = [0 for i in range(4)]\n",
    "        \n",
    "        \n",
    "        #collect loss\n",
    "        classifier_loss = criterion(output_base[:batch_size, :], labels_source) #Loss just for source domain since we do just have labels there\n",
    "        loss_collected += classifier_loss\n",
    "        \n",
    "        #Domain Conditioned Feature Correction#\n",
    "        residual_output_base = classifier_layer(total_feature_residual) #Fully Connected Classifier Layer after appleid attention module \n",
    "        output_residual = class_residual_layer(residual_output_base) #feature correction module\n",
    "        total_output_residual = residual_output_base + output_residual #apply feature correction module\n",
    "        softmax_output_base = softmax_layer(output_base) #activation of class_num output for entropy loss\n",
    "        total_softmax_residual = softmax_layer(total_output_residual)\n",
    "        entropy_loss = EntropyLoss(total_softmax_residual[batch_size:, :]) #entropy loss for all unlabeled target elements\n",
    "        \n",
    "        # alignment of L task-specific feature layers (Here, we have one layer)\n",
    "        #apply MMD between CNN feature extractor and attention module output just for unlabeled target elements\n",
    "        transfer_loss = MMD(features_base[:batch_size, :],total_feature_residual[batch_size:, :])\n",
    "        # alignment of softmax layer\n",
    "        #apply MMD between fully connected layer and feature correction module output just for unlabeled target elements\n",
    "        transfer_loss += MMD(softmax_output_base[:batch_size, :],total_softmax_residual[batch_size:, :], kernel_num=1, fix_sigma=1.68)\n",
    "\n",
    "        ########Backward pass########\n",
    "        optimizer.zero_grad()\n",
    "        total_loss = classifier_loss + alpha_off * transfer_loss + beta_off * entropy_loss #add up losses\n",
    "        total_loss_collected+=total_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    loss_list['train'].append(total_loss_collected/len_data_loader[\"train\"])\n",
    "    writer[\"train\"].add_scalar(f'training loss', total_loss_collected/len_data_loader[\"train\"], epoch)\n",
    "    total_loss_collected = 0    \n",
    "        \n",
    "        \n",
    "    model.train(False)\n",
    "    feature_residual_layer.train(False)\n",
    "    classifier_layer.train(False)\n",
    "    class_residual_layer.train(False)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for windows_target, labels_target in test_loader:\n",
    "            #make predictions for each batch\n",
    "            \n",
    "            \n",
    "            ########Forward pass########\n",
    "            #Domain Conditioned Channel Attention#\n",
    "            features_base = model(windows_target.float()) # Convolutional Feature extractor\n",
    "            features_residual = feature_residual_layer(features_base) # attention module\n",
    "            total_feature_residual = features_base + features_residual #apply attention module\n",
    "            output_base = classifier_layer(features_base) #Fully Connected Classifier Layer\n",
    "\n",
    "\n",
    "            #collect loss\n",
    "            classifier_loss = criterion(output_base, labels) #Loss just for source domain since we do just have labels there\n",
    "            \n",
    "\n",
    "            ########Backward pass########\n",
    "            total_loss = classifier_loss# + alpha_off * transfer_loss + beta_off * entropy_loss #add up losses\n",
    "            total_loss_collected+=total_loss\n",
    "            \n",
    "            \n",
    "            #for each element in batch check if prediction is correct and collect total and correct predictions and labels\n",
    "            for i in range(batch_size):\n",
    "                if len(labels)==4:\n",
    "                    label = labels[i]\n",
    "                    output = torch.argmax(output_base[i])\n",
    "                    if label == output:\n",
    "                        n_correct+=1\n",
    "                        n_class_correct[label]+=1\n",
    "\n",
    "                n_samples+=1\n",
    "                n_class_samples[label]+=1\n",
    "                n_class_samples_out[output]+=1\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "            \n",
    "        loss_list['test'].append(classifier_loss/len_data_loader[\"test\"])\n",
    "        writer[\"test\"].add_scalar(f'training loss', total_loss_collected/len_data_loader[\"test\"], epoch)\n",
    "        total_loss_collected = 0\n",
    "\n",
    "\n",
    "        #calculate total accuracy\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        writer['test'].add_scalar(f'accuracy', acc, epoch)\n",
    "        accuracy_list['test'].append(acc)\n",
    "        \n",
    "        #calculate class accuracy\n",
    "        for i in range(4):\n",
    "            acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "            print(f'Accuracy of {classes[i]}: {acc} %')\n",
    "            \n",
    "        #reset information about labels, predictions\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        n_class_correct = [0 for i in range(4)]\n",
    "        n_class_samples = [0 for i in range(4)]\n",
    "        n_class_samples_out = [0 for i in range(4)]\n",
    "\n",
    "            \n",
    "    \n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} successfull\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "72899743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[660, 660, 660, 660]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_class_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "55ae24c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 660, 660, 1320]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_class_samples_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0731a0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 155, 178, 340]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_class_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "da92b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.ones(6,4)\n",
    "for i in range(test.shape[0]):\n",
    "    test[i,:]+=i\n",
    "for j in range(test.shape[1]):\n",
    "    test[:,j]+=j\n",
    "test1 = test.unsqueeze(0)\n",
    "test1 = test1.expand(test.shape[0], test.shape[0], test.shape[1])\n",
    "test2 = test.unsqueeze(1)\n",
    "test2 = test2.expand(test.shape[0], test.shape[0], test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "eaaa7d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4.],\n",
      "        [2., 3., 4., 5.],\n",
      "        [3., 4., 5., 6.],\n",
      "        [4., 5., 6., 7.],\n",
      "        [5., 6., 7., 8.],\n",
      "        [6., 7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e81195d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 2., 3., 4.],\n",
      "         [2., 3., 4., 5.],\n",
      "         [3., 4., 5., 6.],\n",
      "         [4., 5., 6., 7.],\n",
      "         [5., 6., 7., 8.],\n",
      "         [6., 7., 8., 9.]],\n",
      "\n",
      "        [[1., 2., 3., 4.],\n",
      "         [2., 3., 4., 5.],\n",
      "         [3., 4., 5., 6.],\n",
      "         [4., 5., 6., 7.],\n",
      "         [5., 6., 7., 8.],\n",
      "         [6., 7., 8., 9.]],\n",
      "\n",
      "        [[1., 2., 3., 4.],\n",
      "         [2., 3., 4., 5.],\n",
      "         [3., 4., 5., 6.],\n",
      "         [4., 5., 6., 7.],\n",
      "         [5., 6., 7., 8.],\n",
      "         [6., 7., 8., 9.]],\n",
      "\n",
      "        [[1., 2., 3., 4.],\n",
      "         [2., 3., 4., 5.],\n",
      "         [3., 4., 5., 6.],\n",
      "         [4., 5., 6., 7.],\n",
      "         [5., 6., 7., 8.],\n",
      "         [6., 7., 8., 9.]],\n",
      "\n",
      "        [[1., 2., 3., 4.],\n",
      "         [2., 3., 4., 5.],\n",
      "         [3., 4., 5., 6.],\n",
      "         [4., 5., 6., 7.],\n",
      "         [5., 6., 7., 8.],\n",
      "         [6., 7., 8., 9.]],\n",
      "\n",
      "        [[1., 2., 3., 4.],\n",
      "         [2., 3., 4., 5.],\n",
      "         [3., 4., 5., 6.],\n",
      "         [4., 5., 6., 7.],\n",
      "         [5., 6., 7., 8.],\n",
      "         [6., 7., 8., 9.]]])\n"
     ]
    }
   ],
   "source": [
    "print(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "bddcbb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 2., 3., 4.],\n",
      "         [1., 2., 3., 4.],\n",
      "         [1., 2., 3., 4.],\n",
      "         [1., 2., 3., 4.],\n",
      "         [1., 2., 3., 4.],\n",
      "         [1., 2., 3., 4.]],\n",
      "\n",
      "        [[2., 3., 4., 5.],\n",
      "         [2., 3., 4., 5.],\n",
      "         [2., 3., 4., 5.],\n",
      "         [2., 3., 4., 5.],\n",
      "         [2., 3., 4., 5.],\n",
      "         [2., 3., 4., 5.]],\n",
      "\n",
      "        [[3., 4., 5., 6.],\n",
      "         [3., 4., 5., 6.],\n",
      "         [3., 4., 5., 6.],\n",
      "         [3., 4., 5., 6.],\n",
      "         [3., 4., 5., 6.],\n",
      "         [3., 4., 5., 6.]],\n",
      "\n",
      "        [[4., 5., 6., 7.],\n",
      "         [4., 5., 6., 7.],\n",
      "         [4., 5., 6., 7.],\n",
      "         [4., 5., 6., 7.],\n",
      "         [4., 5., 6., 7.],\n",
      "         [4., 5., 6., 7.]],\n",
      "\n",
      "        [[5., 6., 7., 8.],\n",
      "         [5., 6., 7., 8.],\n",
      "         [5., 6., 7., 8.],\n",
      "         [5., 6., 7., 8.],\n",
      "         [5., 6., 7., 8.],\n",
      "         [5., 6., 7., 8.]],\n",
      "\n",
      "        [[6., 7., 8., 9.],\n",
      "         [6., 7., 8., 9.],\n",
      "         [6., 7., 8., 9.],\n",
      "         [6., 7., 8., 9.],\n",
      "         [6., 7., 8., 9.],\n",
      "         [6., 7., 8., 9.]]])\n"
     ]
    }
   ],
   "source": [
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a0bf2a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  0.,  0.,  0.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [ 2.,  2.,  2.,  2.],\n",
      "         [ 3.,  3.,  3.,  3.],\n",
      "         [ 4.,  4.,  4.,  4.],\n",
      "         [ 5.,  5.,  5.,  5.]],\n",
      "\n",
      "        [[-1., -1., -1., -1.],\n",
      "         [ 0.,  0.,  0.,  0.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [ 2.,  2.,  2.,  2.],\n",
      "         [ 3.,  3.,  3.,  3.],\n",
      "         [ 4.,  4.,  4.,  4.]],\n",
      "\n",
      "        [[-2., -2., -2., -2.],\n",
      "         [-1., -1., -1., -1.],\n",
      "         [ 0.,  0.,  0.,  0.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [ 2.,  2.,  2.,  2.],\n",
      "         [ 3.,  3.,  3.,  3.]],\n",
      "\n",
      "        [[-3., -3., -3., -3.],\n",
      "         [-2., -2., -2., -2.],\n",
      "         [-1., -1., -1., -1.],\n",
      "         [ 0.,  0.,  0.,  0.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [ 2.,  2.,  2.,  2.]],\n",
      "\n",
      "        [[-4., -4., -4., -4.],\n",
      "         [-3., -3., -3., -3.],\n",
      "         [-2., -2., -2., -2.],\n",
      "         [-1., -1., -1., -1.],\n",
      "         [ 0.,  0.,  0.,  0.],\n",
      "         [ 1.,  1.,  1.,  1.]],\n",
      "\n",
      "        [[-5., -5., -5., -5.],\n",
      "         [-4., -4., -4., -4.],\n",
      "         [-3., -3., -3., -3.],\n",
      "         [-2., -2., -2., -2.],\n",
      "         [-1., -1., -1., -1.],\n",
      "         [ 0.,  0.,  0.,  0.]]])\n"
     ]
    }
   ],
   "source": [
    "print((test1-test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "17eaf61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.,   4.,   8.,  12.,  16.,  20.],\n",
      "        [ -4.,   0.,   4.,   8.,  12.,  16.],\n",
      "        [ -8.,  -4.,   0.,   4.,   8.,  12.],\n",
      "        [-12.,  -8.,  -4.,   0.,   4.,   8.],\n",
      "        [-16., -12.,  -8.,  -4.,   0.,   4.],\n",
      "        [-20., -16., -12.,  -8.,  -4.,   0.]])\n"
     ]
    }
   ],
   "source": [
    "print((test1-test2).sum(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "093fe394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum((test1-test2).sum(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff07f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
