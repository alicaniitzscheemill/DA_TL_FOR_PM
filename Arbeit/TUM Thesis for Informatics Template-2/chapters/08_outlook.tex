\chapter{Outlook}
There are still several open and interesting topics, which are worth to be investigated for the PHM of BSDs. GANs were already investigated for the PHM of other industrial parts. Zhang et al \cite{Zhang2019} developed a wasserstein distance guided multi-adversarial network for the prediction of the degradation status of rolling bearing. The development and training of such methods might be more complex. Anyhow, the adversarial training is especially promising for the extraction of domain-invariant features \cite{Zhang2019}. A less complex method, which uses similar mechanisms as GANs was presented by Guo et al \cite{Guo2019}. They developed a deep learning-based model which reduces the domain discrepancy based on a MMD-loss. In addition, a domain classifier is included, which tries to predict the domain for each processed sample. The feature extractor is optimized based on a weighted loss, which minimizes the source CE- and MMD-loss and maximizes the domain discriminator loss. There are quite interesting applications that use deep belief networks (DBN) \cite{ZHAO2019213} for PHM applications. Deep belief networks (DBN) contain several stacked restricted Boltzmann machines (RBMs). The training of DBNs is separated in two phases. First, all RBMs are optimized individually. Afterward, the DBN is fine-tuned to solve the classification task by applying backpropagation on all RBM layers simultaneously. One has to remember that the complex model training of DBNs and GANs can lead to difficulties when applying such networks on noisy and disturbed real-world vibration signals. This might lead to instabilities during training. Other preprocessing steps, like wavelet transforms or FFT, could be included to feed more expressive data to the neural networks. The windowing requirements differ for the machine excitements (constant speed excitement, direction change excitement and sweep excitement). Generally, when choosing the window size, there is a trade-off between the window size and the number of windows generated from the data. Big windows capture more degradation-related patterns of the vibration signals. Contrariwise, the training of neural networks is improved with an increasing amount of samples and therefore windows.  More intelligent windowing functions could improve the PHM performance, by individually adapting the window size to the consistency and periodicity of the data.






\begin{comment}
Also the preprocessing of the recorded machine signals could be improved. In this thesis a simple windowing function was used to separate the data in shorter sequences. Generally, the generated windows should capture the degradation related patterns of the vibration signals. For this reason, the windows should be adjusted to the consistency and periodicity of the data. The windowing requirements differ for the machine excitements (constant speed excitement, direction change excitement and sweep excitement). Generally, when choosing the window size, there is a trade-off between the window size and the number of windows generated from the data. Both extremes (few big windows and numerous small windows) might lead to problems during the training. The PHM results might be improved by applying an adaptive preprocessing to generate data windows of suitable length, which are well synchronized with the data. Lastly, also the potential performance gains due to the combination of several signals could be investigated in more detail.
\end{comment}