\chapter{Conclusion}\label{chapter:conclusion}
In this thesis a deep learning-based PHM system of BSDs was successfully extended with a domain adaption module. A novel way of reducing the domain discrepancy in the network's feature extractor was developed. Applying the MMD-loss in the layers of the CNN and classifier reduces the model's domain discrepancy more efficiently than the more traditional approaches, which just apply the MMD-loss in the task specific layers. This greater efficiency is mainly reflected in the overall performance and the increased stability during the training. A novel labeled MMD-loss, which considers the source and target labels, revealed the main deficit of the unlabeled MMD-loss. Oftentimes, the unlabeled MMD-loss can not improve the separability equally good as the compactness and domain discrepancy throughout the training. The GAMMA choice is highly relevant for the PHM performance and has to be picked individually for each signal. An imperfect GAMMA choice reduces the separability and leads to a trivial optimization solution, where the feature representation of all samples collapse at a small subset. 
